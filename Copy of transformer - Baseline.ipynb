{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"papermill":{"duration":654.273766,"end_time":"2020-12-19T21:56:32.593054","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2020-12-19T21:45:38.319288","version":"2.1.0"},"colab":{"name":"transformer-baseline.ipynb","provenance":[],"collapsed_sections":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"13a0a25ba2744f4e8169996cfe4f0e1c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b6ef6ce16979486eb09047eca2659196","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_307fa7f104864d65af9059adb6637a9f","IPY_MODEL_cd2c634868974bc882db5a42d96cdf5d"]}},"b6ef6ce16979486eb09047eca2659196":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"307fa7f104864d65af9059adb6637a9f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_460b039a60d54ba4b378ca7bb3aa54d1","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":1875000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1875000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e1de71e769ef4e61be93f0a53bd77c54"}},"cd2c634868974bc882db5a42d96cdf5d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3b58971568904b048eaaafdd1fb73141","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1875000/1875000 [23:56&lt;00:00, 1304.83it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b2d20c1190034d108e421155369f1bca"}},"460b039a60d54ba4b378ca7bb3aa54d1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e1de71e769ef4e61be93f0a53bd77c54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3b58971568904b048eaaafdd1fb73141":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b2d20c1190034d108e421155369f1bca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eb68c79468504f14bcfdc6a85a16b2b2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cc783e6b050645908a56b3f3bc59e295","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8a44dc431f4240ebb963b0b7434f7794","IPY_MODEL_b6a028a8cd734a049ee0ad5b726f0455"]}},"cc783e6b050645908a56b3f3bc59e295":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8a44dc431f4240ebb963b0b7434f7794":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4969c11082bb471e99a7adf6e0fdd491","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":9,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":9,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ce850903f5a74485867622293c96fe42"}},"b6a028a8cd734a049ee0ad5b726f0455":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d4999b4236da47e8b0e93a690b57ee2e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9/9 [15:15&lt;00:00, 101.78s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ce91da6b0f71438da4860ca1a4d94664"}},"4969c11082bb471e99a7adf6e0fdd491":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ce850903f5a74485867622293c96fe42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d4999b4236da47e8b0e93a690b57ee2e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ce91da6b0f71438da4860ca1a4d94664":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eb4e67a35d904e06a15cfe3da02ba85d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_50fe860952f54712a15fcbfdf03e314f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8a28c8d5f18348cfaa9a082cbee290fc","IPY_MODEL_00666d96d6f0492c97b6c8990dc2d134"]}},"50fe860952f54712a15fcbfdf03e314f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8a28c8d5f18348cfaa9a082cbee290fc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f4daef016ec14f498abc0d04e73146d5","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":10,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":10,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e7fd19b1ac1e4e8b86d479050fa8f2ae"}},"00666d96d6f0492c97b6c8990dc2d134":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_eb299d3fe506465eb40b211abd99bd1e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 10/10 [00:02&lt;00:00,  3.65it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8709de796bf041e8812a2ef323d40e9c"}},"f4daef016ec14f498abc0d04e73146d5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e7fd19b1ac1e4e8b86d479050fa8f2ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eb299d3fe506465eb40b211abd99bd1e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8709de796bf041e8812a2ef323d40e9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"69ab76bb417743f88049c020989acf79":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b6df59940cd342c0b238a10642f18f58","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fc1ae8716dc74fd18897781c36cf6e53","IPY_MODEL_77331773856043ee91c0b00437224339"]}},"b6df59940cd342c0b238a10642f18f58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fc1ae8716dc74fd18897781c36cf6e53":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_cc91ff975dda47f9b661cec2f1c45ccb","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":10,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":10,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3c08e1180e53424ea15ac58c0a355c83"}},"77331773856043ee91c0b00437224339":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cfbbc0d77ea34b6496bc349b4111db93","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 10/10 [00:02&lt;00:00,  3.68it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_07b94aad2a7e4c75a7d05ab649e1ea8f"}},"cc91ff975dda47f9b661cec2f1c45ccb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3c08e1180e53424ea15ac58c0a355c83":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cfbbc0d77ea34b6496bc349b4111db93":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"07b94aad2a7e4c75a7d05ab649e1ea8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d9024560e67f4d478bf99d5262cef382":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c0517d1bff024064af00842db343e1d4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_083d3d85c0f646ad8579499f035b2fe9","IPY_MODEL_a504a0cb613e42b68709e55687096916"]}},"c0517d1bff024064af00842db343e1d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"083d3d85c0f646ad8579499f035b2fe9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b77b1ce9da354401842dd13a54a58f75","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":10,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":10,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_09b1ea1c8f3f44b6808ceac5034ae718"}},"a504a0cb613e42b68709e55687096916":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4c837a1f791f4aad927baa263e8f5049","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 10/10 [00:02&lt;00:00,  3.66it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a40cf36bf60d4b2ba4c02f369f188f5d"}},"b77b1ce9da354401842dd13a54a58f75":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"09b1ea1c8f3f44b6808ceac5034ae718":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4c837a1f791f4aad927baa263e8f5049":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a40cf36bf60d4b2ba4c02f369f188f5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"812e2d6d03864e2cacb709c7ca553c64":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3004f7c0786f4081a868be7d5b71dbfb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2a7a123aee1840e6810b71ea6a4e8eec","IPY_MODEL_76d65cf11931463582a0e743196fd07e"]}},"3004f7c0786f4081a868be7d5b71dbfb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2a7a123aee1840e6810b71ea6a4e8eec":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3b2cc8d01abf4b6fbf7e271cbba2e447","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":10,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":10,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_904d577e69284ec1a0c7ec47cd0fe62e"}},"76d65cf11931463582a0e743196fd07e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_eb5b141910f640a9a077f76ca9cb67f8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 10/10 [00:02&lt;00:00,  3.56it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a09c2e0ba9714eb6a7897cc7b517f725"}},"3b2cc8d01abf4b6fbf7e271cbba2e447":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"904d577e69284ec1a0c7ec47cd0fe62e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eb5b141910f640a9a077f76ca9cb67f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a09c2e0ba9714eb6a7897cc7b517f725":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"629bb46197814b599177ffe1b53f29a1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_97ed707856b147ae9653094e699a92f7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e7b6c1e9a7f343f39b62dcce928ac776","IPY_MODEL_1e7d1eec48884a02affd0e5d44ffb2bc"]}},"97ed707856b147ae9653094e699a92f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e7b6c1e9a7f343f39b62dcce928ac776":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b083c7767c4f4328b3c563d959942e26","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":10,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":10,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2c9e2ef3d4154db28476f6ed06408506"}},"1e7d1eec48884a02affd0e5d44ffb2bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3c066e5447c64dd2aab5530641b23c8e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 10/10 [00:02&lt;00:00,  3.64it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_420a1be829a945d28cba697e9af8f366"}},"b083c7767c4f4328b3c563d959942e26":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2c9e2ef3d4154db28476f6ed06408506":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3c066e5447c64dd2aab5530641b23c8e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"420a1be829a945d28cba697e9af8f366":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PFBBlwXwJCOr","executionInfo":{"status":"ok","timestamp":1613564993323,"user_tz":-540,"elapsed":4998,"user":{"displayName":"기석윤","photoUrl":"","userId":"09664814525927757322"}},"outputId":"74a97624-2ca8-4bd6-a845-4d80d3af4b99"},"source":["!pip install iterative-stratification"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting iterative-stratification\n","  Downloading https://files.pythonhosted.org/packages/9d/79/9ba64c8c07b07b8b45d80725b2ebd7b7884701c1da34f70d4749f7b45f9a/iterative_stratification-0.1.6-py3-none-any.whl\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from iterative-stratification) (1.19.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from iterative-stratification) (1.4.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from iterative-stratification) (0.22.2.post1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->iterative-stratification) (1.0.0)\n","Installing collected packages: iterative-stratification\n","Successfully installed iterative-stratification-0.1.6\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P_Pc0n7jwQSq","executionInfo":{"status":"ok","timestamp":1613565535548,"user_tz":-540,"elapsed":547215,"user":{"displayName":"기석윤","photoUrl":"","userId":"09664814525927757322"}},"outputId":"3f13a315-687f-4d1d-b5e3-beb17c6b97cd"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7bJ70Ws1wSGD","executionInfo":{"status":"ok","timestamp":1613565535548,"user_tz":-540,"elapsed":547214,"user":{"displayName":"기석윤","photoUrl":"","userId":"09664814525927757322"}}},"source":["#경로 설정\r\n","import os\r\n","os.chdir('/content/drive/My Drive/Colab Notebooks/운동동작분류AI경진대회')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"_kg_hide-output":false,"execution":{"iopub.execute_input":"2020-12-19T21:45:42.915933Z","iopub.status.busy":"2020-12-19T21:45:42.915215Z","iopub.status.idle":"2020-12-19T21:45:55.422401Z","shell.execute_reply":"2020-12-19T21:45:55.423089Z"},"papermill":{"duration":12.539859,"end_time":"2020-12-19T21:45:55.423292","exception":false,"start_time":"2020-12-19T21:45:42.883433","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"9bbPFoUlwP3L","executionInfo":{"status":"ok","timestamp":1613565539887,"user_tz":-540,"elapsed":551549,"user":{"displayName":"기석윤","photoUrl":"","userId":"09664814525927757322"}},"outputId":"91a12b46-4e12-4710-8ba5-a5c23645f00c"},"source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","import tensorflow as tf\n","tf.random.set_seed(42)\n","import tensorflow.keras.backend as K\n","import tensorflow.keras.layers as layers\n","from tensorflow.keras.callbacks import Callback, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n","\n","import os, gc, random, datetime\n","import pandas as pd\n","import numpy as np\n","import xgboost as xgb\n","from sklearn.metrics import roc_auc_score, roc_curve\n","import matplotlib.pyplot as plt\n","from tqdm.notebook import tqdm\n","from joblib import dump, load\n","from time import time\n","import scipy as sp\n","import scipy.fftpack\n","\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","\n","print(\"Tensorflow version \" + tf.__version__)\n","AUTO = tf.data.experimental.AUTOTUNE"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Tensorflow version 2.4.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.021446,"end_time":"2020-12-19T21:45:55.576052","exception":false,"start_time":"2020-12-19T21:45:55.554606","status":"completed"},"tags":[],"id":"dC9e5tXuwP3M"},"source":["# Preprocessing"]},{"cell_type":"code","metadata":{"id":"A77rJfaswP3M","executionInfo":{"status":"ok","timestamp":1613565546873,"user_tz":-540,"elapsed":558533,"user":{"displayName":"기석윤","photoUrl":"","userId":"09664814525927757322"}}},"source":["# 데이터 불러오기\n","\n","path = './data/'\n","train = pd.read_csv(path + 'train_features.csv')\n","train_label = pd.read_csv(path + 'train_labels.csv')\n","test = pd.read_csv(path + 'test_features.csv')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"I4bg_yTDwP3M","executionInfo":{"status":"ok","timestamp":1613565633325,"user_tz":-540,"elapsed":644984,"user":{"displayName":"기석윤","photoUrl":"","userId":"09664814525927757322"}}},"source":["# Pre-Processing Effect on the Accuracy of Event-Based Activity Segmentation and Classification through Inertial Sensors \n","# https://www.researchgate.net/publication/281836367_Pre-Processing_Effect_on_the_Accuracy_of_Event-Based_Activity_Segmentation_and_Classification_through_Inertial_Sensors\n","\n","train['acc_t'] = train.apply(lambda x : (x['acc_x']**2 + x['acc_y'] **2 + x['acc_z'] **2)**(1/2), axis=1)\n","test['acc_t'] = test.apply(lambda x : (x['acc_x']**2 + x['acc_y'] **2 + x['acc_z'] **2)**(1/2), axis=1)\n","train['gy_t'] = train.apply(lambda x : (x['gy_x']**2 + x['gy_y'] **2 + x['gy_z'] **2)**(1/2), axis=1)\n","test['gy_t'] = test.apply(lambda x : (x['gy_x']**2 + x['gy_y'] **2 + x['gy_z'] **2)**(1/2), axis=1)\n","\n","# SVM selected features\n","train['mean'] = train[['acc_x','acc_y']].mean(axis=1)\n","train['median'] = train[['acc_y', 'gy_z', 'gy_t']].median(axis=1)\n","train['standard_deviation'] = train[['acc_x', 'acc_y']].std(axis=1)\n","train['interquartile'] = train.quantile(.75, axis=1) - train.quantile(.25, axis=1)\n","\n","test['mean'] = test[['acc_x','acc_y']].mean(axis=1)\n","test['median'] = test[['acc_y', 'gy_z', 'gy_t']].median(axis=1)\n","test['standard_deviation'] = test[['acc_x', 'acc_y']].std(axis=1)\n","test['interquartile'] = test.quantile(.75, axis=1) - test.quantile(.25, axis=1)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"gHMRT0CZwP3N"},"source":["x = np.array(train.iloc[:,2:]).reshape(-1, 600, 12)\n","y = tf.keras.utils.to_categorical(train_label['label'])\n","test = np.array(test.iloc[:,2:]).reshape(-1, 600, 12)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8XY0T8yquzpe"},"source":["## 도비님의 데이터 증강 방법"]},{"cell_type":"code","metadata":{"id":"ClQxLhFSuuIn"},"source":["# 26번을 제외한 id 리스트\r\n","feature = list(train_label[train_label['label'] != 26]['id'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["13a0a25ba2744f4e8169996cfe4f0e1c","b6ef6ce16979486eb09047eca2659196","307fa7f104864d65af9059adb6637a9f","cd2c634868974bc882db5a42d96cdf5d","460b039a60d54ba4b378ca7bb3aa54d1","e1de71e769ef4e61be93f0a53bd77c54","3b58971568904b048eaaafdd1fb73141","b2d20c1190034d108e421155369f1bca"]},"id":"0lkMdYWDu6eS","executionInfo":{"status":"ok","timestamp":1613462545698,"user_tz":-540,"elapsed":591852,"user":{"displayName":"기석윤","photoUrl":"","userId":"09664814525927757322"}},"outputId":"f725bb4f-1208-4a4a-8a3f-4427058933b0"},"source":["# train 데이터에서 26번을 삭제시킨다.\r\n","temp = []\r\n","for n in tqdm(range(train.shape[0])):\r\n","    if train['id'][n] in feature:\r\n","        temp.append(train.iloc[n])"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"13a0a25ba2744f4e8169996cfe4f0e1c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1875000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XnUHYQ1iu8E9"},"source":["# 26번을 삭제시킨 데이터프레임\r\n","without = pd.DataFrame(data=np.array(temp), columns=train.columns)\r\n","without = without.astype({'id':int, 'time':int})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mKBjbqeDvCk9"},"source":["without_train = np.array(without.iloc[:,2:]).reshape(-1, 600, 12)\r\n","without_label = train_label[train_label['label'] != 26]['label']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["eb68c79468504f14bcfdc6a85a16b2b2","cc783e6b050645908a56b3f3bc59e295","8a44dc431f4240ebb963b0b7434f7794","b6a028a8cd734a049ee0ad5b726f0455","4969c11082bb471e99a7adf6e0fdd491","ce850903f5a74485867622293c96fe42","d4999b4236da47e8b0e93a690b57ee2e","ce91da6b0f71438da4860ca1a4d94664"]},"id":"6TigcFKFvU9f","executionInfo":{"status":"ok","timestamp":1613462565078,"user_tz":-540,"elapsed":611220,"user":{"displayName":"기석윤","photoUrl":"","userId":"09664814525927757322"}},"outputId":"90c0e70c-2ad2-4be2-e032-6a57b3f496d5"},"source":["def aug(data, shift):\r\n","    shift_data = np.roll(data, shift, axis=1)\r\n","    return shift_data\r\n","\r\n","# 데이터 증강\r\n","shift_data = []\r\n","shift_label = []\r\n","for n in tqdm(range(1, 10)):\r\n","    shifted = aug(without_train, n*60)\r\n","    shift_data.append(shifted)\r\n","    shift_label.append(without_label)\r\n","\r\n","shift_data = np.array(shift_data).reshape(-1,600,12)\r\n","shift_label = np.array(shift_label).reshape(-1,1)\r\n","shift_categorical = tf.keras.utils.to_categorical(shift_label)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eb68c79468504f14bcfdc6a85a16b2b2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cLCjZo9rvU6t","executionInfo":{"status":"ok","timestamp":1613462565423,"user_tz":-540,"elapsed":611561,"user":{"displayName":"기석윤","photoUrl":"","userId":"09664814525927757322"}},"outputId":"a5174fac-b28d-4076-9649-999c1621fbdb"},"source":["# 원본 데이터와 증강 데이터 합치기\r\n","concat_train = np.concatenate((x, shift_data), axis=0)\r\n","concat_label = np.concatenate((y, shift_categorical), axis=0)\r\n","print(concat_train.shape)\r\n","print(concat_label.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(17588, 600, 12)\n","(17588, 61)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2uzqCgtG0e4j"},"source":["del x, shift_data, y, shift_categorical, without, without_train, without_label, feature, temp"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.034259,"end_time":"2020-12-19T21:47:05.668897","exception":false,"start_time":"2020-12-19T21:47:05.634638","status":"completed"},"tags":[],"id":"ruDx0aTTwP3N"},"source":["# Training"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.033446,"end_time":"2020-12-19T21:47:05.735558","exception":false,"start_time":"2020-12-19T21:47:05.702112","status":"completed"},"tags":[],"id":"jJCWdNkWwP3N"},"source":["Base Transformer structure from https://www.tensorflow.org/tutorials/text/transformer, modified with Swish activation function."]},{"cell_type":"code","metadata":{"_kg_hide-input":false,"execution":{"iopub.execute_input":"2020-12-19T21:47:05.822914Z","iopub.status.busy":"2020-12-19T21:47:05.821803Z","iopub.status.idle":"2020-12-19T21:47:05.866016Z","shell.execute_reply":"2020-12-19T21:47:05.865400Z"},"papermill":{"duration":0.09191,"end_time":"2020-12-19T21:47:05.866129","exception":false,"start_time":"2020-12-19T21:47:05.774219","status":"completed"},"tags":[],"id":"b7k4RMZhwP3N"},"source":["def scaled_dot_product_attention(q, k, v, mask):\n","    \"\"\"Calculate the attention weights.\n","    q, k, v must have matching leading dimensions.\n","    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n","    The mask has different shapes depending on its type(padding or look ahead) \n","    but it must be broadcastable for addition.\n","\n","    Args:\n","    q: query shape == (..., seq_len_q, depth)\n","    k: key shape == (..., seq_len_k, depth)\n","    v: value shape == (..., seq_len_v, depth_v)\n","    mask: Float tensor with shape broadcastable \n","          to (..., seq_len_q, seq_len_k). Defaults to None.\n","\n","    Returns:\n","    output, attention_weights\n","    \"\"\"\n","\n","    matmul_qk = tf.matmul(q, k, transpose_b = True)  # (..., seq_len_q, seq_len_k)\n","\n","    # scale matmul_qk\n","    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n","    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n","\n","    # add the mask to the scaled tensor.\n","    if mask is not None:\n","        \n","        scaled_attention_logits += (mask * -1e9)  \n","\n","    # softmax is normalized on the last axis (seq_len_k) so that the scores\n","    # add up to 1.\n","    attention_weights = tf.nn.softmax(scaled_attention_logits, axis = -1)  # (..., seq_len_q, seq_len_k)\n","\n","    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n","\n","    return output, attention_weights\n","\n","class MultiHeadAttention(tf.keras.layers.Layer):\n","    \n","    def __init__(self, d_model, num_heads):\n","        \n","        super(MultiHeadAttention, self).__init__()\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","\n","        assert d_model % self.num_heads == 0\n","\n","        self.depth = d_model // self.num_heads\n","\n","        self.wq = tf.keras.layers.Dense(d_model)\n","        self.wk = tf.keras.layers.Dense(d_model)\n","        self.wv = tf.keras.layers.Dense(d_model)\n","\n","        self.dense = tf.keras.layers.Dense(d_model)\n","        \n","    def split_heads(self, x, batch_size):\n","        \"\"\"Split the last dimension into (num_heads, depth).\n","        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n","        \"\"\"\n","        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","        return tf.transpose(x, perm = [0, 2, 1, 3])\n","    \n","    def call(self, v, k, q, mask):\n","        \n","        batch_size = tf.shape(q)[0]\n","\n","        q = self.wq(q)  # (batch_size, seq_len, d_model)\n","        k = self.wk(k)  # (batch_size, seq_len, d_model)\n","        v = self.wv(v)  # (batch_size, seq_len, d_model)\n","\n","        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n","        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n","        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n","\n","        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n","        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n","        scaled_attention, attention_weights = scaled_dot_product_attention(\n","            q, k, v, mask)\n","\n","        scaled_attention = tf.transpose(scaled_attention, perm = [0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n","\n","        concat_attention = tf.reshape(scaled_attention, \n","                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n","\n","        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n","        \n","        return output, attention_weights\n","\n","def point_wise_feed_forward_network(d_model, dff):\n","    \n","    return tf.keras.Sequential([\n","      tf.keras.layers.Dense(dff, activation = 'relu'),  # (batch_size, seq_len, dff)\n","      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n","    ])\n","\n","class EncoderLayer(tf.keras.layers.Layer):\n","    \n","    def __init__(self, d_model, num_heads, dff, rate = 0.1):\n","        \n","        super(EncoderLayer, self).__init__()\n","\n","        self.mha = MultiHeadAttention(d_model, num_heads)\n","        self.ffn = point_wise_feed_forward_network(d_model, dff)\n","\n","        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n","        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n","\n","        self.dropout1 = tf.keras.layers.Dropout(rate)\n","        self.dropout2 = tf.keras.layers.Dropout(rate)\n","\n","    def call(self, x, training, mask):\n","\n","        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n","        attn_output = self.dropout1(attn_output, training = training)\n","        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n","\n","        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n","        ffn_output = self.dropout2(ffn_output, training = training)\n","        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n","\n","        return out2\n","\n","class TransformerEncoder(tf.keras.layers.Layer):\n","    \n","    def __init__(self, num_layers, d_model, num_heads, dff, \n","                 maximum_position_encoding, rate = 0.1):\n","        \n","        super(TransformerEncoder, self).__init__()\n","\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","        self.num_heads = num_heads\n","        self.dff = dff\n","        self.maximum_position_encoding = maximum_position_encoding\n","        self.rate = rate\n","\n","#         self.pos_encoding = positional_encoding(self.maximum_position_encoding, \n","#                                                 self.d_model)\n","#         self.embedding = tf.keras.layers.Dense(self.d_model)\n","        self.pos_emb = tf.keras.layers.Embedding(input_dim = self.maximum_position_encoding, \n","                                                 output_dim = self.d_model)\n","\n","        self.enc_layers = [EncoderLayer(self.d_model, self.num_heads, self.dff, self.rate) \n","                           for _ in range(self.num_layers)]\n","\n","        self.dropout = tf.keras.layers.Dropout(self.rate)\n","        \n","    def get_config(self):\n","\n","        config = super().get_config().copy()\n","        config.update({\n","            'num_layers': self.num_layers,\n","            'd_model': self.d_model,\n","            'num_heads': self.num_heads,\n","            'dff': self.dff,\n","            'maximum_position_encoding': self.maximum_position_encoding,\n","            'dropout': self.dropout,\n","        })\n","        return config\n","\n","    def call(self, x, training, mask = None):\n","\n","        seq_len = tf.shape(x)[1]\n","\n","        # adding embedding and position encoding.\n","#         x += self.pos_encoding[:, :seq_len, :]\n","#         x = self.embedding(x)\n","        positions = tf.range(start = 0, limit = seq_len, delta = 1)\n","        x += self.pos_emb(positions)\n","\n","        x = self.dropout(x, training = training)\n","\n","        for i in range(self.num_layers):\n","\n","            x = self.enc_layers[i](x, training, mask)\n","\n","        return x  # (batch_size, input_seq_len, d_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2020-12-19T21:47:05.924111Z","iopub.status.busy":"2020-12-19T21:47:05.923351Z","iopub.status.idle":"2020-12-19T21:47:05.927506Z","shell.execute_reply":"2020-12-19T21:47:05.927026Z"},"papermill":{"duration":0.038039,"end_time":"2020-12-19T21:47:05.927604","exception":false,"start_time":"2020-12-19T21:47:05.889565","status":"completed"},"tags":[],"id":"mOCptCFxwP3P"},"source":["def create_transformer_model(num_columns, num_labels, num_layers, d_model, num_heads, dff, window_size, dropout_rate, weight_decay, label_smoothing, learning_rate):\n","    \n","    inp = tf.keras.layers.Input(shape = (window_size, num_columns))\n","    x = tf.keras.layers.BatchNormalization()(inp)\n","    x = tf.keras.layers.Dense(d_model)(x)\n","    x = tf.keras.layers.BatchNormalization()(x)\n","    x = tf.keras.layers.Activation('relu')(x)\n","    x = tf.keras.layers.SpatialDropout1D(dropout_rate)(x)\n","    x = TransformerEncoder(num_layers, d_model, num_heads, dff, window_size, dropout_rate)(x)\n","    out = tf.keras.layers.Dense(num_labels, activation = 'softmax')(x[:, -1, :])\n","    \n","    model = tf.keras.models.Model(inputs = inp, outputs = out)\n","    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['AUC'])\n","    \n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2020-12-19T21:47:06.026885Z","iopub.status.busy":"2020-12-19T21:47:06.025060Z","iopub.status.idle":"2020-12-19T21:47:06.027550Z","shell.execute_reply":"2020-12-19T21:47:06.028046Z"},"papermill":{"duration":0.031196,"end_time":"2020-12-19T21:47:06.028159","exception":false,"start_time":"2020-12-19T21:47:05.996963","status":"completed"},"tags":[],"id":"M8HPyemgwP3R"},"source":["batch_size = 32\n","num_layers = 1\n","d_model = 128\n","num_heads = 1\n","dff = 128\n","window_size = 600\n","dropout_rate = 0.15\n","weight_decay = 0\n","label_smoothing = 1e-2\n","learning_rate = 1e-3\n","verbose = 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2020-12-19T21:47:12.495194Z","iopub.status.busy":"2020-12-19T21:47:12.494436Z","iopub.status.idle":"2020-12-19T21:48:42.358496Z","shell.execute_reply":"2020-12-19T21:48:42.357889Z"},"papermill":{"duration":89.899584,"end_time":"2020-12-19T21:48:42.358608","exception":false,"start_time":"2020-12-19T21:47:12.459024","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["eb4e67a35d904e06a15cfe3da02ba85d","50fe860952f54712a15fcbfdf03e314f","8a28c8d5f18348cfaa9a082cbee290fc","00666d96d6f0492c97b6c8990dc2d134","f4daef016ec14f498abc0d04e73146d5","e7fd19b1ac1e4e8b86d479050fa8f2ae","eb299d3fe506465eb40b211abd99bd1e","8709de796bf041e8812a2ef323d40e9c","69ab76bb417743f88049c020989acf79","b6df59940cd342c0b238a10642f18f58","fc1ae8716dc74fd18897781c36cf6e53","77331773856043ee91c0b00437224339","cc91ff975dda47f9b661cec2f1c45ccb","3c08e1180e53424ea15ac58c0a355c83","cfbbc0d77ea34b6496bc349b4111db93","07b94aad2a7e4c75a7d05ab649e1ea8f","d9024560e67f4d478bf99d5262cef382","c0517d1bff024064af00842db343e1d4","083d3d85c0f646ad8579499f035b2fe9","a504a0cb613e42b68709e55687096916","b77b1ce9da354401842dd13a54a58f75","09b1ea1c8f3f44b6808ceac5034ae718","4c837a1f791f4aad927baa263e8f5049","a40cf36bf60d4b2ba4c02f369f188f5d","812e2d6d03864e2cacb709c7ca553c64","3004f7c0786f4081a868be7d5b71dbfb","2a7a123aee1840e6810b71ea6a4e8eec","76d65cf11931463582a0e743196fd07e","3b2cc8d01abf4b6fbf7e271cbba2e447","904d577e69284ec1a0c7ec47cd0fe62e","eb5b141910f640a9a077f76ca9cb67f8","a09c2e0ba9714eb6a7897cc7b517f725","629bb46197814b599177ffe1b53f29a1","97ed707856b147ae9653094e699a92f7","e7b6c1e9a7f343f39b62dcce928ac776","1e7d1eec48884a02affd0e5d44ffb2bc","b083c7767c4f4328b3c563d959942e26","2c9e2ef3d4154db28476f6ed06408506","3c066e5447c64dd2aab5530641b23c8e","420a1be829a945d28cba697e9af8f366"]},"id":"q5wj-CmawP3R","executionInfo":{"status":"ok","timestamp":1613471395300,"user_tz":-540,"elapsed":4281529,"user":{"displayName":"기석윤","photoUrl":"","userId":"09664814525927757322"}},"outputId":"d98f4329-35d6-4d1d-ac96-a2f4aed0f536"},"source":["# 모델 1번: Transformer\n","\n","def build_transformer(split_num, train, target, test, rnd):\n","    start_time_fold = time()\n","    # return train pred prob and test pred prob \n","    test_pred = np.zeros((test.shape[0], 61))\n","\n","    ckp_path = 'transformer.hdf5'\n","\n","    rlr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 3, verbose = verbose, min_delta = 1e-4, mode = 'min')\n","    ckp = ModelCheckpoint(ckp_path, monitor = 'val_loss', verbose = 0, save_best_only = True, save_weights_only = True, mode = 'min')\n","    es = EarlyStopping(monitor = 'val_loss', min_delta = 1e-4, patience = 4, mode = 'min', baseline = None, restore_best_weights = True, verbose = 0)\n","\n","    mskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","    for train_idx, val_idx in mskf.split(train, target):\n","\n","        # split train, validation set\n","        X = train[train_idx]\n","        y = target[train_idx]\n","        valid_x = train[val_idx]\n","        valid_y = target[val_idx]\n","\n","        #가벼운 모델 생성\n","        model = create_transformer_model(train.shape[2], 61, num_layers, d_model, num_heads, dff, window_size, dropout_rate, weight_decay, label_smoothing, learning_rate)\n","\n","        model.fit(X, y, epochs = 100,\n","                  validation_data = (valid_x, valid_y),\n","                  batch_size = batch_size,\n","                  callbacks = [rlr, ckp, es],\n","                  verbose = verbose)\n","        \n","        # save feat\n","        model.load_weights(ckp_path)\n","\n","        # 테스트 데이터 증강\n","        shift_test = []\n","        for n in range(10):\n","            shifted = aug(test, n*60)\n","            test_pred += model.predict(shifted)/(split_num*10)\n","        \n","        # release\n","        del model\n","        gc.collect()\n","        print('  ==============================================================================================  ')\n","\n","        \n","    return test_pred\n","\n","transformer_train1, transformer_test1 = build_transformer(5, concat_train, concat_label, test, 1)\n","transformer_train2, transformer_test2 = build_transformer(5, concat_train, concat_label, test, 2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","440/440 [==============================] - 15s 30ms/step - loss: 3.1127 - auc: 0.8338 - val_loss: 1.7794 - val_auc: 0.9600\n","Epoch 2/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.9249 - auc: 0.9562 - val_loss: 1.3764 - val_auc: 0.9763\n","Epoch 3/100\n","440/440 [==============================] - 13s 30ms/step - loss: 1.6059 - auc: 0.9694 - val_loss: 1.2295 - val_auc: 0.9801\n","Epoch 4/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.4120 - auc: 0.9758 - val_loss: 1.0556 - val_auc: 0.9849\n","Epoch 5/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.2631 - auc: 0.9808 - val_loss: 0.9872 - val_auc: 0.9873\n","Epoch 6/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.2017 - auc: 0.9825 - val_loss: 0.8578 - val_auc: 0.9915\n","Epoch 7/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.1077 - auc: 0.9845 - val_loss: 0.8202 - val_auc: 0.9914\n","Epoch 8/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.0421 - auc: 0.9869 - val_loss: 0.7643 - val_auc: 0.9924\n","Epoch 9/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.9844 - auc: 0.9884 - val_loss: 0.6972 - val_auc: 0.9933\n","Epoch 10/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.9507 - auc: 0.9887 - val_loss: 0.6821 - val_auc: 0.9938\n","Epoch 11/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.8664 - auc: 0.9908 - val_loss: 0.6301 - val_auc: 0.9951\n","Epoch 12/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.8388 - auc: 0.9916 - val_loss: 0.6199 - val_auc: 0.9943\n","Epoch 13/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.8374 - auc: 0.9908 - val_loss: 0.5818 - val_auc: 0.9955\n","Epoch 14/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.7775 - auc: 0.9921 - val_loss: 0.5590 - val_auc: 0.9952\n","Epoch 15/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.7429 - auc: 0.9926 - val_loss: 0.5157 - val_auc: 0.9960\n","Epoch 16/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.7369 - auc: 0.9932 - val_loss: 0.5166 - val_auc: 0.9963\n","Epoch 17/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.7196 - auc: 0.9933 - val_loss: 0.4904 - val_auc: 0.9967\n","Epoch 18/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6969 - auc: 0.9939 - val_loss: 0.4815 - val_auc: 0.9966\n","Epoch 19/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6876 - auc: 0.9932 - val_loss: 0.4389 - val_auc: 0.9974\n","Epoch 20/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6504 - auc: 0.9946 - val_loss: 0.4189 - val_auc: 0.9972\n","Epoch 21/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6326 - auc: 0.9941 - val_loss: 0.4290 - val_auc: 0.9970\n","Epoch 22/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6268 - auc: 0.9940 - val_loss: 0.3881 - val_auc: 0.9979\n","Epoch 23/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6028 - auc: 0.9949 - val_loss: 0.3613 - val_auc: 0.9978\n","Epoch 24/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6168 - auc: 0.9945 - val_loss: 0.3500 - val_auc: 0.9978\n","Epoch 25/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5627 - auc: 0.9947 - val_loss: 0.3840 - val_auc: 0.9977\n","Epoch 26/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5655 - auc: 0.9955 - val_loss: 0.3563 - val_auc: 0.9985\n","Epoch 27/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5765 - auc: 0.9951 - val_loss: 0.3349 - val_auc: 0.9984\n","Epoch 28/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5443 - auc: 0.9948 - val_loss: 0.3612 - val_auc: 0.9977\n","Epoch 29/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5314 - auc: 0.9957 - val_loss: 0.3431 - val_auc: 0.9986\n","Epoch 30/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5367 - auc: 0.9952 - val_loss: 0.3116 - val_auc: 0.9988\n","Epoch 31/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5091 - auc: 0.9958 - val_loss: 0.3004 - val_auc: 0.9986\n","Epoch 32/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5181 - auc: 0.9960 - val_loss: 0.2984 - val_auc: 0.9986\n","Epoch 33/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5151 - auc: 0.9953 - val_loss: 0.2961 - val_auc: 0.9982\n","Epoch 34/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5226 - auc: 0.9950 - val_loss: 0.2999 - val_auc: 0.9984\n","Epoch 35/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.4739 - auc: 0.9960 - val_loss: 0.3015 - val_auc: 0.9987\n","Epoch 36/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.4977 - auc: 0.9953 - val_loss: 0.3238 - val_auc: 0.9979\n","\n","Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n","Epoch 37/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.4469 - auc: 0.9969 - val_loss: 0.2359 - val_auc: 0.9990\n","Epoch 38/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3699 - auc: 0.9977 - val_loss: 0.2260 - val_auc: 0.9990\n","Epoch 39/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3560 - auc: 0.9978 - val_loss: 0.2151 - val_auc: 0.9992\n","Epoch 40/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3556 - auc: 0.9984 - val_loss: 0.2118 - val_auc: 0.9994\n","Epoch 41/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3510 - auc: 0.9980 - val_loss: 0.2082 - val_auc: 0.9992\n","Epoch 42/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3319 - auc: 0.9985 - val_loss: 0.2085 - val_auc: 0.9994\n","Epoch 43/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3246 - auc: 0.9984 - val_loss: 0.2038 - val_auc: 0.9990\n","Epoch 44/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3360 - auc: 0.9982 - val_loss: 0.2044 - val_auc: 0.9992\n","Epoch 45/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3330 - auc: 0.9986 - val_loss: 0.2057 - val_auc: 0.9990\n","Epoch 46/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3276 - auc: 0.9981 - val_loss: 0.2004 - val_auc: 0.9991\n","Epoch 47/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3222 - auc: 0.9980 - val_loss: 0.1983 - val_auc: 0.9990\n","Epoch 48/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3164 - auc: 0.9985 - val_loss: 0.1912 - val_auc: 0.9992\n","Epoch 49/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3117 - auc: 0.9986 - val_loss: 0.1991 - val_auc: 0.9990\n","Epoch 50/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3208 - auc: 0.9978 - val_loss: 0.1922 - val_auc: 0.9993\n","Epoch 51/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3190 - auc: 0.9985 - val_loss: 0.1892 - val_auc: 0.9991\n","Epoch 52/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3309 - auc: 0.9982 - val_loss: 0.1873 - val_auc: 0.9992\n","Epoch 53/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3213 - auc: 0.9982 - val_loss: 0.1876 - val_auc: 0.9992\n","Epoch 54/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3192 - auc: 0.9983 - val_loss: 0.1854 - val_auc: 0.9990\n","Epoch 55/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3068 - auc: 0.9985 - val_loss: 0.1825 - val_auc: 0.9992\n","Epoch 56/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3091 - auc: 0.9983 - val_loss: 0.1806 - val_auc: 0.9990\n","Epoch 57/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2987 - auc: 0.9986 - val_loss: 0.1813 - val_auc: 0.9992\n","Epoch 58/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3091 - auc: 0.9982 - val_loss: 0.1811 - val_auc: 0.9990\n","Epoch 59/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2979 - auc: 0.9981 - val_loss: 0.1834 - val_auc: 0.9992\n","\n","Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n","Epoch 60/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3024 - auc: 0.9985 - val_loss: 0.1795 - val_auc: 0.9992\n","Epoch 61/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3008 - auc: 0.9987 - val_loss: 0.1789 - val_auc: 0.9992\n","Epoch 62/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2882 - auc: 0.9983 - val_loss: 0.1764 - val_auc: 0.9992\n","Epoch 63/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2749 - auc: 0.9987 - val_loss: 0.1767 - val_auc: 0.9992\n","Epoch 64/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2867 - auc: 0.9983 - val_loss: 0.1765 - val_auc: 0.9992\n","Epoch 65/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2910 - auc: 0.9984 - val_loss: 0.1748 - val_auc: 0.9992\n","Epoch 66/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2981 - auc: 0.9985 - val_loss: 0.1749 - val_auc: 0.9992\n","Epoch 67/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2913 - auc: 0.9982 - val_loss: 0.1762 - val_auc: 0.9992\n","Epoch 68/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2861 - auc: 0.9987 - val_loss: 0.1761 - val_auc: 0.9992\n","\n","Epoch 00068: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n","Epoch 69/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2807 - auc: 0.9986 - val_loss: 0.1743 - val_auc: 0.9992\n","Epoch 70/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2867 - auc: 0.9984 - val_loss: 0.1739 - val_auc: 0.9992\n","Epoch 71/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2770 - auc: 0.9986 - val_loss: 0.1747 - val_auc: 0.9992\n","Epoch 72/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3176 - auc: 0.9983 - val_loss: 0.1747 - val_auc: 0.9992\n","Epoch 73/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2881 - auc: 0.9983 - val_loss: 0.1759 - val_auc: 0.9992\n","\n","Epoch 00073: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n","Epoch 74/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2874 - auc: 0.9984 - val_loss: 0.1740 - val_auc: 0.9992\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eb4e67a35d904e06a15cfe3da02ba85d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","  ==============================================================================================  \n","Epoch 1/100\n","440/440 [==============================] - 15s 31ms/step - loss: 3.1020 - auc: 0.8366 - val_loss: 1.8115 - val_auc: 0.9630\n","Epoch 2/100\n","440/440 [==============================] - 13s 30ms/step - loss: 2.0098 - auc: 0.9511 - val_loss: 1.3679 - val_auc: 0.9775\n","Epoch 3/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.6392 - auc: 0.9679 - val_loss: 1.1351 - val_auc: 0.9836\n","Epoch 4/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.4521 - auc: 0.9723 - val_loss: 0.9991 - val_auc: 0.9881\n","Epoch 5/100\n","440/440 [==============================] - 13s 30ms/step - loss: 1.3102 - auc: 0.9784 - val_loss: 0.9621 - val_auc: 0.9881\n","Epoch 6/100\n","440/440 [==============================] - 13s 30ms/step - loss: 1.1943 - auc: 0.9825 - val_loss: 0.8560 - val_auc: 0.9906\n","Epoch 7/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.1052 - auc: 0.9847 - val_loss: 0.8334 - val_auc: 0.9911\n","Epoch 8/100\n","440/440 [==============================] - 13s 30ms/step - loss: 1.0470 - auc: 0.9865 - val_loss: 0.7293 - val_auc: 0.9933\n","Epoch 9/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.9775 - auc: 0.9895 - val_loss: 0.6871 - val_auc: 0.9948\n","Epoch 10/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.9339 - auc: 0.9890 - val_loss: 0.6919 - val_auc: 0.9937\n","Epoch 11/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.9070 - auc: 0.9895 - val_loss: 0.6386 - val_auc: 0.9944\n","Epoch 12/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.8762 - auc: 0.9907 - val_loss: 0.6075 - val_auc: 0.9947\n","Epoch 13/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.8147 - auc: 0.9917 - val_loss: 0.6001 - val_auc: 0.9950\n","Epoch 14/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.8050 - auc: 0.9916 - val_loss: 0.5833 - val_auc: 0.9949\n","Epoch 15/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.7590 - auc: 0.9926 - val_loss: 0.5426 - val_auc: 0.9953\n","Epoch 16/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.7204 - auc: 0.9930 - val_loss: 0.5311 - val_auc: 0.9963\n","Epoch 17/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.7397 - auc: 0.9933 - val_loss: 0.5381 - val_auc: 0.9971\n","Epoch 18/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6993 - auc: 0.9930 - val_loss: 0.4994 - val_auc: 0.9970\n","Epoch 19/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6861 - auc: 0.9936 - val_loss: 0.4728 - val_auc: 0.9967\n","Epoch 20/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6645 - auc: 0.9940 - val_loss: 0.4662 - val_auc: 0.9970\n","Epoch 21/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6630 - auc: 0.9940 - val_loss: 0.4368 - val_auc: 0.9972\n","Epoch 22/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6293 - auc: 0.9941 - val_loss: 0.4349 - val_auc: 0.9972\n","Epoch 23/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6558 - auc: 0.9936 - val_loss: 0.4097 - val_auc: 0.9971\n","Epoch 24/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5832 - auc: 0.9956 - val_loss: 0.4037 - val_auc: 0.9971\n","Epoch 25/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5720 - auc: 0.9955 - val_loss: 0.3836 - val_auc: 0.9977\n","Epoch 26/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5797 - auc: 0.9945 - val_loss: 0.3662 - val_auc: 0.9975\n","Epoch 27/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5699 - auc: 0.9949 - val_loss: 0.3735 - val_auc: 0.9975\n","Epoch 28/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5460 - auc: 0.9951 - val_loss: 0.3616 - val_auc: 0.9975\n","Epoch 29/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5364 - auc: 0.9954 - val_loss: 0.3642 - val_auc: 0.9979\n","Epoch 30/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5691 - auc: 0.9944 - val_loss: 0.3351 - val_auc: 0.9984\n","Epoch 31/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5349 - auc: 0.9953 - val_loss: 0.3285 - val_auc: 0.9979\n","Epoch 32/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.4992 - auc: 0.9959 - val_loss: 0.3589 - val_auc: 0.9977\n","Epoch 33/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.4922 - auc: 0.9958 - val_loss: 0.3472 - val_auc: 0.9973\n","Epoch 34/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5199 - auc: 0.9948 - val_loss: 0.3298 - val_auc: 0.9972\n","\n","Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n","Epoch 35/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.4472 - auc: 0.9961 - val_loss: 0.2548 - val_auc: 0.9982\n","Epoch 36/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3823 - auc: 0.9975 - val_loss: 0.2461 - val_auc: 0.9984\n","Epoch 37/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3782 - auc: 0.9978 - val_loss: 0.2381 - val_auc: 0.9983\n","Epoch 38/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3679 - auc: 0.9981 - val_loss: 0.2410 - val_auc: 0.9983\n","Epoch 39/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3672 - auc: 0.9978 - val_loss: 0.2310 - val_auc: 0.9985\n","Epoch 40/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3547 - auc: 0.9980 - val_loss: 0.2269 - val_auc: 0.9983\n","Epoch 41/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3518 - auc: 0.9979 - val_loss: 0.2256 - val_auc: 0.9986\n","Epoch 42/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3480 - auc: 0.9981 - val_loss: 0.2212 - val_auc: 0.9984\n","Epoch 43/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3470 - auc: 0.9982 - val_loss: 0.2187 - val_auc: 0.9986\n","Epoch 44/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3587 - auc: 0.9976 - val_loss: 0.2159 - val_auc: 0.9985\n","Epoch 45/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3350 - auc: 0.9980 - val_loss: 0.2200 - val_auc: 0.9984\n","Epoch 46/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3399 - auc: 0.9977 - val_loss: 0.2181 - val_auc: 0.9984\n","Epoch 47/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3428 - auc: 0.9980 - val_loss: 0.2156 - val_auc: 0.9982\n","Epoch 48/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3324 - auc: 0.9977 - val_loss: 0.2131 - val_auc: 0.9984\n","Epoch 49/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3269 - auc: 0.9978 - val_loss: 0.2094 - val_auc: 0.9985\n","Epoch 50/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3355 - auc: 0.9982 - val_loss: 0.2034 - val_auc: 0.9985\n","Epoch 51/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3066 - auc: 0.9986 - val_loss: 0.2044 - val_auc: 0.9987\n","Epoch 52/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3248 - auc: 0.9983 - val_loss: 0.2076 - val_auc: 0.9984\n","Epoch 53/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3271 - auc: 0.9984 - val_loss: 0.2053 - val_auc: 0.9984\n","\n","Epoch 00053: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n","Epoch 54/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3205 - auc: 0.9977 - val_loss: 0.2010 - val_auc: 0.9986\n","Epoch 55/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3086 - auc: 0.9987 - val_loss: 0.2012 - val_auc: 0.9986\n","Epoch 56/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3096 - auc: 0.9984 - val_loss: 0.1986 - val_auc: 0.9986\n","Epoch 57/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3050 - auc: 0.9984 - val_loss: 0.1986 - val_auc: 0.9987\n","Epoch 58/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3316 - auc: 0.9984 - val_loss: 0.1990 - val_auc: 0.9986\n","Epoch 59/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3066 - auc: 0.9988 - val_loss: 0.2021 - val_auc: 0.9985\n","\n","Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n","Epoch 60/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3246 - auc: 0.9981 - val_loss: 0.1995 - val_auc: 0.9986\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"69ab76bb417743f88049c020989acf79","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","  ==============================================================================================  \n","Epoch 1/100\n","440/440 [==============================] - 15s 31ms/step - loss: 3.0901 - auc: 0.8367 - val_loss: 1.8356 - val_auc: 0.9588\n","Epoch 2/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.9623 - auc: 0.9533 - val_loss: 1.3354 - val_auc: 0.9780\n","Epoch 3/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.6016 - auc: 0.9672 - val_loss: 1.1802 - val_auc: 0.9827\n","Epoch 4/100\n","440/440 [==============================] - 13s 30ms/step - loss: 1.4118 - auc: 0.9750 - val_loss: 1.0491 - val_auc: 0.9871\n","Epoch 5/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.3130 - auc: 0.9796 - val_loss: 1.0026 - val_auc: 0.9868\n","Epoch 6/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.1739 - auc: 0.9831 - val_loss: 0.8699 - val_auc: 0.9895\n","Epoch 7/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.1014 - auc: 0.9850 - val_loss: 0.8397 - val_auc: 0.9911\n","Epoch 8/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.0627 - auc: 0.9851 - val_loss: 0.7676 - val_auc: 0.9927\n","Epoch 9/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.9764 - auc: 0.9888 - val_loss: 0.7469 - val_auc: 0.9928\n","Epoch 10/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.9318 - auc: 0.9891 - val_loss: 0.7061 - val_auc: 0.9935\n","Epoch 11/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.8947 - auc: 0.9895 - val_loss: 0.6543 - val_auc: 0.9945\n","Epoch 12/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.8692 - auc: 0.9910 - val_loss: 0.6336 - val_auc: 0.9944\n","Epoch 13/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.8189 - auc: 0.9916 - val_loss: 0.5891 - val_auc: 0.9952\n","Epoch 14/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.8077 - auc: 0.9916 - val_loss: 0.5791 - val_auc: 0.9955\n","Epoch 15/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.7781 - auc: 0.9921 - val_loss: 0.5484 - val_auc: 0.9962\n","Epoch 16/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.7412 - auc: 0.9928 - val_loss: 0.5151 - val_auc: 0.9965\n","Epoch 17/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.7202 - auc: 0.9929 - val_loss: 0.5344 - val_auc: 0.9965\n","Epoch 18/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6713 - auc: 0.9942 - val_loss: 0.5005 - val_auc: 0.9961\n","Epoch 19/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6860 - auc: 0.9935 - val_loss: 0.4699 - val_auc: 0.9965\n","Epoch 20/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6544 - auc: 0.9947 - val_loss: 0.4588 - val_auc: 0.9974\n","Epoch 21/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6369 - auc: 0.9943 - val_loss: 0.4537 - val_auc: 0.9969\n","Epoch 22/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6093 - auc: 0.9951 - val_loss: 0.4305 - val_auc: 0.9976\n","Epoch 23/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6074 - auc: 0.9950 - val_loss: 0.4260 - val_auc: 0.9969\n","Epoch 24/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6141 - auc: 0.9939 - val_loss: 0.3978 - val_auc: 0.9984\n","Epoch 25/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5955 - auc: 0.9949 - val_loss: 0.3686 - val_auc: 0.9986\n","Epoch 26/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5774 - auc: 0.9952 - val_loss: 0.3772 - val_auc: 0.9980\n","Epoch 27/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.5639 - auc: 0.9950 - val_loss: 0.3507 - val_auc: 0.9987\n","Epoch 28/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.5509 - auc: 0.9954 - val_loss: 0.3447 - val_auc: 0.9977\n","Epoch 29/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5068 - auc: 0.9957 - val_loss: 0.3618 - val_auc: 0.9985\n","Epoch 30/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5479 - auc: 0.9949 - val_loss: 0.3652 - val_auc: 0.9979\n","Epoch 31/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5136 - auc: 0.9955 - val_loss: 0.3277 - val_auc: 0.9981\n","Epoch 32/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5178 - auc: 0.9959 - val_loss: 0.2970 - val_auc: 0.9987\n","Epoch 33/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5028 - auc: 0.9963 - val_loss: 0.3199 - val_auc: 0.9984\n","Epoch 34/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.4834 - auc: 0.9966 - val_loss: 0.3177 - val_auc: 0.9982\n","Epoch 35/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5038 - auc: 0.9950 - val_loss: 0.2974 - val_auc: 0.9990\n","\n","Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n","Epoch 36/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.4024 - auc: 0.9977 - val_loss: 0.2404 - val_auc: 0.9991\n","Epoch 37/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3665 - auc: 0.9982 - val_loss: 0.2337 - val_auc: 0.9991\n","Epoch 38/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3747 - auc: 0.9978 - val_loss: 0.2292 - val_auc: 0.9993\n","Epoch 39/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3644 - auc: 0.9982 - val_loss: 0.2250 - val_auc: 0.9992\n","Epoch 40/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3654 - auc: 0.9982 - val_loss: 0.2250 - val_auc: 0.9992\n","Epoch 41/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3464 - auc: 0.9981 - val_loss: 0.2208 - val_auc: 0.9990\n","Epoch 42/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3560 - auc: 0.9982 - val_loss: 0.2101 - val_auc: 0.9995\n","Epoch 43/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3411 - auc: 0.9985 - val_loss: 0.2089 - val_auc: 0.9994\n","Epoch 44/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3394 - auc: 0.9981 - val_loss: 0.2114 - val_auc: 0.9992\n","Epoch 45/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3441 - auc: 0.9980 - val_loss: 0.2047 - val_auc: 0.9992\n","Epoch 46/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3263 - auc: 0.9984 - val_loss: 0.2051 - val_auc: 0.9992\n","Epoch 47/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3344 - auc: 0.9980 - val_loss: 0.2035 - val_auc: 0.9991\n","Epoch 48/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3319 - auc: 0.9979 - val_loss: 0.2020 - val_auc: 0.9991\n","Epoch 49/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3268 - auc: 0.9985 - val_loss: 0.1980 - val_auc: 0.9991\n","Epoch 50/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3290 - auc: 0.9980 - val_loss: 0.1960 - val_auc: 0.9991\n","Epoch 51/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3130 - auc: 0.9984 - val_loss: 0.1983 - val_auc: 0.9992\n","Epoch 52/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3288 - auc: 0.9984 - val_loss: 0.1949 - val_auc: 0.9993\n","Epoch 53/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3333 - auc: 0.9980 - val_loss: 0.1967 - val_auc: 0.9991\n","Epoch 54/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3151 - auc: 0.9980 - val_loss: 0.1901 - val_auc: 0.9995\n","Epoch 55/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3141 - auc: 0.9986 - val_loss: 0.1877 - val_auc: 0.9996\n","Epoch 56/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3040 - auc: 0.9985 - val_loss: 0.1917 - val_auc: 0.9993\n","Epoch 57/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3117 - auc: 0.9981 - val_loss: 0.1885 - val_auc: 0.9991\n","Epoch 58/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3112 - auc: 0.9984 - val_loss: 0.1860 - val_auc: 0.9991\n","Epoch 59/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3132 - auc: 0.9982 - val_loss: 0.1877 - val_auc: 0.9993\n","Epoch 60/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3056 - auc: 0.9984 - val_loss: 0.1868 - val_auc: 0.9993\n","Epoch 61/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3158 - auc: 0.9983 - val_loss: 0.1848 - val_auc: 0.9991\n","Epoch 62/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2997 - auc: 0.9984 - val_loss: 0.1815 - val_auc: 0.9992\n","Epoch 63/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3119 - auc: 0.9984 - val_loss: 0.1822 - val_auc: 0.9990\n","Epoch 64/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2931 - auc: 0.9988 - val_loss: 0.1798 - val_auc: 0.9992\n","Epoch 65/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3058 - auc: 0.9980 - val_loss: 0.1807 - val_auc: 0.9990\n","Epoch 66/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3022 - auc: 0.9985 - val_loss: 0.1763 - val_auc: 0.9992\n","Epoch 67/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2958 - auc: 0.9980 - val_loss: 0.1758 - val_auc: 0.9992\n","Epoch 68/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3106 - auc: 0.9983 - val_loss: 0.1798 - val_auc: 0.9989\n","Epoch 69/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2986 - auc: 0.9979 - val_loss: 0.1733 - val_auc: 0.9990\n","Epoch 70/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2934 - auc: 0.9986 - val_loss: 0.1814 - val_auc: 0.9990\n","Epoch 71/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2905 - auc: 0.9984 - val_loss: 0.1794 - val_auc: 0.9990\n","Epoch 72/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2955 - auc: 0.9982 - val_loss: 0.1751 - val_auc: 0.9990\n","\n","Epoch 00072: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n","Epoch 73/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.2914 - auc: 0.9985 - val_loss: 0.1734 - val_auc: 0.9990\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d9024560e67f4d478bf99d5262cef382","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","  ==============================================================================================  \n","Epoch 1/100\n","440/440 [==============================] - 15s 30ms/step - loss: 3.0787 - auc: 0.8417 - val_loss: 1.8675 - val_auc: 0.9584\n","Epoch 2/100\n","440/440 [==============================] - 13s 30ms/step - loss: 1.9414 - auc: 0.9559 - val_loss: 1.3733 - val_auc: 0.9761\n","Epoch 3/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.6113 - auc: 0.9683 - val_loss: 1.1937 - val_auc: 0.9812\n","Epoch 4/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.3836 - auc: 0.9755 - val_loss: 1.0156 - val_auc: 0.9866\n","Epoch 5/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.2843 - auc: 0.9789 - val_loss: 0.9422 - val_auc: 0.9884\n","Epoch 6/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.1670 - auc: 0.9829 - val_loss: 0.8551 - val_auc: 0.9906\n","Epoch 7/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.1119 - auc: 0.9838 - val_loss: 0.7707 - val_auc: 0.9910\n","Epoch 8/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.0584 - auc: 0.9861 - val_loss: 0.7205 - val_auc: 0.9928\n","Epoch 9/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.9618 - auc: 0.9888 - val_loss: 0.6970 - val_auc: 0.9936\n","Epoch 10/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.9140 - auc: 0.9895 - val_loss: 0.6432 - val_auc: 0.9944\n","Epoch 11/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.8811 - auc: 0.9904 - val_loss: 0.6155 - val_auc: 0.9958\n","Epoch 12/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.8457 - auc: 0.9904 - val_loss: 0.5483 - val_auc: 0.9961\n","Epoch 13/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.7702 - auc: 0.9922 - val_loss: 0.5629 - val_auc: 0.9958\n","Epoch 14/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.7561 - auc: 0.9923 - val_loss: 0.5075 - val_auc: 0.9970\n","Epoch 15/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.7613 - auc: 0.9928 - val_loss: 0.5237 - val_auc: 0.9972\n","Epoch 16/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6991 - auc: 0.9939 - val_loss: 0.4595 - val_auc: 0.9976\n","Epoch 17/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6879 - auc: 0.9938 - val_loss: 0.4561 - val_auc: 0.9976\n","Epoch 18/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.7001 - auc: 0.9939 - val_loss: 0.4440 - val_auc: 0.9976\n","Epoch 19/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6485 - auc: 0.9944 - val_loss: 0.4102 - val_auc: 0.9977\n","Epoch 20/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6740 - auc: 0.9930 - val_loss: 0.3994 - val_auc: 0.9979\n","Epoch 21/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6294 - auc: 0.9943 - val_loss: 0.4076 - val_auc: 0.9979\n","Epoch 22/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.6229 - auc: 0.9941 - val_loss: 0.3736 - val_auc: 0.9982\n","Epoch 23/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5816 - auc: 0.9948 - val_loss: 0.3676 - val_auc: 0.9974\n","Epoch 24/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5883 - auc: 0.9945 - val_loss: 0.3391 - val_auc: 0.9981\n","Epoch 25/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5821 - auc: 0.9952 - val_loss: 0.3619 - val_auc: 0.9982\n","Epoch 26/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.5587 - auc: 0.9952 - val_loss: 0.3456 - val_auc: 0.9981\n","Epoch 27/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.5640 - auc: 0.9952 - val_loss: 0.3446 - val_auc: 0.9984\n","\n","Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n","Epoch 28/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.5043 - auc: 0.9963 - val_loss: 0.2566 - val_auc: 0.9991\n","Epoch 29/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.4375 - auc: 0.9973 - val_loss: 0.2509 - val_auc: 0.9991\n","Epoch 30/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.4147 - auc: 0.9977 - val_loss: 0.2452 - val_auc: 0.9991\n","Epoch 31/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3989 - auc: 0.9978 - val_loss: 0.2354 - val_auc: 0.9992\n","Epoch 32/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.4163 - auc: 0.9976 - val_loss: 0.2377 - val_auc: 0.9992\n","Epoch 33/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3972 - auc: 0.9980 - val_loss: 0.2317 - val_auc: 0.9992\n","Epoch 34/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.4155 - auc: 0.9971 - val_loss: 0.2274 - val_auc: 0.9992\n","Epoch 35/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3869 - auc: 0.9980 - val_loss: 0.2238 - val_auc: 0.9992\n","Epoch 36/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3846 - auc: 0.9979 - val_loss: 0.2235 - val_auc: 0.9992\n","Epoch 37/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.4052 - auc: 0.9975 - val_loss: 0.2192 - val_auc: 0.9992\n","Epoch 38/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3830 - auc: 0.9975 - val_loss: 0.2147 - val_auc: 0.9992\n","Epoch 39/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3844 - auc: 0.9977 - val_loss: 0.2149 - val_auc: 0.9992\n","Epoch 40/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3739 - auc: 0.9978 - val_loss: 0.2138 - val_auc: 0.9992\n","Epoch 41/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3744 - auc: 0.9981 - val_loss: 0.2076 - val_auc: 0.9993\n","Epoch 42/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3765 - auc: 0.9976 - val_loss: 0.2068 - val_auc: 0.9993\n","Epoch 43/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3667 - auc: 0.9977 - val_loss: 0.2041 - val_auc: 0.9991\n","Epoch 44/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3632 - auc: 0.9979 - val_loss: 0.2117 - val_auc: 0.9992\n","Epoch 45/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3786 - auc: 0.9975 - val_loss: 0.2037 - val_auc: 0.9993\n","Epoch 46/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3602 - auc: 0.9978 - val_loss: 0.2026 - val_auc: 0.9993\n","Epoch 47/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3575 - auc: 0.9981 - val_loss: 0.2100 - val_auc: 0.9992\n","Epoch 48/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3570 - auc: 0.9981 - val_loss: 0.2008 - val_auc: 0.9991\n","Epoch 49/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.3719 - auc: 0.9970 - val_loss: 0.1952 - val_auc: 0.9993\n","Epoch 50/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3558 - auc: 0.9980 - val_loss: 0.1967 - val_auc: 0.9993\n","Epoch 51/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3664 - auc: 0.9977 - val_loss: 0.1964 - val_auc: 0.9991\n","Epoch 52/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3368 - auc: 0.9981 - val_loss: 0.1969 - val_auc: 0.9993\n","\n","Epoch 00052: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n","Epoch 53/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3496 - auc: 0.9980 - val_loss: 0.1932 - val_auc: 0.9993\n","Epoch 54/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3436 - auc: 0.9979 - val_loss: 0.1928 - val_auc: 0.9993\n","Epoch 55/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3477 - auc: 0.9983 - val_loss: 0.1914 - val_auc: 0.9993\n","Epoch 56/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3384 - auc: 0.9980 - val_loss: 0.1906 - val_auc: 0.9993\n","Epoch 57/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3547 - auc: 0.9976 - val_loss: 0.1901 - val_auc: 0.9993\n","Epoch 58/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3458 - auc: 0.9981 - val_loss: 0.1911 - val_auc: 0.9993\n","Epoch 59/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3496 - auc: 0.9982 - val_loss: 0.1886 - val_auc: 0.9993\n","Epoch 60/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3503 - auc: 0.9977 - val_loss: 0.1878 - val_auc: 0.9993\n","Epoch 61/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3567 - auc: 0.9980 - val_loss: 0.1883 - val_auc: 0.9993\n","Epoch 62/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3229 - auc: 0.9983 - val_loss: 0.1888 - val_auc: 0.9993\n","Epoch 63/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3374 - auc: 0.9981 - val_loss: 0.1879 - val_auc: 0.9993\n","\n","Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n","Epoch 64/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3424 - auc: 0.9981 - val_loss: 0.1880 - val_auc: 0.9993\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"812e2d6d03864e2cacb709c7ca553c64","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","  ==============================================================================================  \n","Epoch 1/100\n","440/440 [==============================] - 15s 31ms/step - loss: 3.0140 - auc: 0.8486 - val_loss: 1.7700 - val_auc: 0.9623\n","Epoch 2/100\n","440/440 [==============================] - 13s 30ms/step - loss: 1.9675 - auc: 0.9528 - val_loss: 1.3447 - val_auc: 0.9810\n","Epoch 3/100\n","440/440 [==============================] - 13s 30ms/step - loss: 1.5591 - auc: 0.9697 - val_loss: 1.1718 - val_auc: 0.9832\n","Epoch 4/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.4104 - auc: 0.9771 - val_loss: 1.0134 - val_auc: 0.9890\n","Epoch 5/100\n","440/440 [==============================] - 13s 29ms/step - loss: 1.2923 - auc: 0.9796 - val_loss: 0.9371 - val_auc: 0.9891\n","Epoch 6/100\n","440/440 [==============================] - 13s 30ms/step - loss: 1.1939 - auc: 0.9832 - val_loss: 0.8852 - val_auc: 0.9908\n","Epoch 7/100\n","440/440 [==============================] - 13s 30ms/step - loss: 1.1063 - auc: 0.9856 - val_loss: 0.8048 - val_auc: 0.9928\n","Epoch 8/100\n","440/440 [==============================] - 13s 30ms/step - loss: 1.0127 - auc: 0.9877 - val_loss: 0.7899 - val_auc: 0.9921\n","Epoch 9/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.9730 - auc: 0.9889 - val_loss: 0.6945 - val_auc: 0.9942\n","Epoch 10/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.9273 - auc: 0.9888 - val_loss: 0.6476 - val_auc: 0.9953\n","Epoch 11/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.8838 - auc: 0.9907 - val_loss: 0.6128 - val_auc: 0.9948\n","Epoch 12/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.8404 - auc: 0.9912 - val_loss: 0.5992 - val_auc: 0.9954\n","Epoch 13/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.8130 - auc: 0.9919 - val_loss: 0.5799 - val_auc: 0.9961\n","Epoch 14/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.7888 - auc: 0.9920 - val_loss: 0.5394 - val_auc: 0.9964\n","Epoch 15/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.7540 - auc: 0.9927 - val_loss: 0.5196 - val_auc: 0.9971\n","Epoch 16/100\n","440/440 [==============================] - 13s 29ms/step - loss: 0.7200 - auc: 0.9932 - val_loss: 0.5270 - val_auc: 0.9975\n","Epoch 17/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.7465 - auc: 0.9923 - val_loss: 0.4914 - val_auc: 0.9970\n","Epoch 18/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.6969 - auc: 0.9939 - val_loss: 0.4871 - val_auc: 0.9974\n","Epoch 19/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.6810 - auc: 0.9941 - val_loss: 0.4415 - val_auc: 0.9974\n","Epoch 20/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.6243 - auc: 0.9944 - val_loss: 0.4351 - val_auc: 0.9976\n","Epoch 21/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.6476 - auc: 0.9939 - val_loss: 0.4231 - val_auc: 0.9981\n","Epoch 22/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.6100 - auc: 0.9954 - val_loss: 0.4077 - val_auc: 0.9978\n","Epoch 23/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.6352 - auc: 0.9936 - val_loss: 0.4289 - val_auc: 0.9971\n","Epoch 24/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.6202 - auc: 0.9943 - val_loss: 0.4267 - val_auc: 0.9968\n","Epoch 25/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.5955 - auc: 0.9942 - val_loss: 0.3773 - val_auc: 0.9983\n","Epoch 26/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.5797 - auc: 0.9949 - val_loss: 0.3775 - val_auc: 0.9980\n","Epoch 27/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.5898 - auc: 0.9952 - val_loss: 0.3701 - val_auc: 0.9976\n","Epoch 28/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.5395 - auc: 0.9953 - val_loss: 0.3628 - val_auc: 0.9978\n","Epoch 29/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.5718 - auc: 0.9948 - val_loss: 0.3251 - val_auc: 0.9984\n","Epoch 30/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.5448 - auc: 0.9957 - val_loss: 0.3555 - val_auc: 0.9981\n","Epoch 31/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.5241 - auc: 0.9958 - val_loss: 0.3335 - val_auc: 0.9987\n","Epoch 32/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.5113 - auc: 0.9957 - val_loss: 0.3439 - val_auc: 0.9978\n","\n","Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n","Epoch 33/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.4527 - auc: 0.9969 - val_loss: 0.2582 - val_auc: 0.9989\n","Epoch 34/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3896 - auc: 0.9979 - val_loss: 0.2542 - val_auc: 0.9986\n","Epoch 35/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3892 - auc: 0.9975 - val_loss: 0.2482 - val_auc: 0.9989\n","Epoch 36/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3826 - auc: 0.9979 - val_loss: 0.2458 - val_auc: 0.9988\n","Epoch 37/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3822 - auc: 0.9975 - val_loss: 0.2355 - val_auc: 0.9990\n","Epoch 38/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3635 - auc: 0.9980 - val_loss: 0.2341 - val_auc: 0.9990\n","Epoch 39/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3660 - auc: 0.9976 - val_loss: 0.2271 - val_auc: 0.9990\n","Epoch 40/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3569 - auc: 0.9979 - val_loss: 0.2259 - val_auc: 0.9990\n","Epoch 41/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3581 - auc: 0.9979 - val_loss: 0.2250 - val_auc: 0.9993\n","Epoch 42/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3653 - auc: 0.9979 - val_loss: 0.2172 - val_auc: 0.9991\n","Epoch 43/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3722 - auc: 0.9975 - val_loss: 0.2208 - val_auc: 0.9989\n","Epoch 44/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3306 - auc: 0.9985 - val_loss: 0.2242 - val_auc: 0.9989\n","Epoch 45/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3455 - auc: 0.9983 - val_loss: 0.2176 - val_auc: 0.9989\n","\n","Epoch 00045: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n","Epoch 46/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3474 - auc: 0.9982 - val_loss: 0.2137 - val_auc: 0.9989\n","Epoch 47/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3372 - auc: 0.9983 - val_loss: 0.2116 - val_auc: 0.9989\n","Epoch 48/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3457 - auc: 0.9980 - val_loss: 0.2126 - val_auc: 0.9989\n","Epoch 49/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3373 - auc: 0.9983 - val_loss: 0.2122 - val_auc: 0.9989\n","Epoch 50/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3345 - auc: 0.9984 - val_loss: 0.2128 - val_auc: 0.9989\n","\n","Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n","Epoch 51/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3363 - auc: 0.9982 - val_loss: 0.2113 - val_auc: 0.9989\n","Epoch 52/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3327 - auc: 0.9986 - val_loss: 0.2128 - val_auc: 0.9989\n","Epoch 53/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3335 - auc: 0.9982 - val_loss: 0.2128 - val_auc: 0.9989\n","Epoch 54/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3572 - auc: 0.9977 - val_loss: 0.2131 - val_auc: 0.9989\n","\n","Epoch 00054: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n","Epoch 55/100\n","440/440 [==============================] - 13s 30ms/step - loss: 0.3232 - auc: 0.9985 - val_loss: 0.2125 - val_auc: 0.9989\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"629bb46197814b599177ffe1b53f29a1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","  ==============================================================================================  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XzsnZO_JnacA"},"source":["sample_submssion = pd.read_csv(path + 'sample_submission.csv')\r\n","sample_submssion.iloc[:,1:] = transformer_test_shifted\r\n","sample_submssion.to_csv(\"transformer_shifted.csv\", index = False)\r\n","sample_submssion"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"52PJ3lmypBBm"},"source":["# https://www.kaggle.com/gogo827jz/jane-street-ffill-transformer-baseline\r\n","# https://wikidocs.net/31379\r\n","# https://www.tensorflow.org/tutorials/text/transformer"],"execution_count":null,"outputs":[]}]}
