{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 메모리 할당 문제\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Activation, Convolution2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout, Conv2D,MaxPool2D, ZeroPadding2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.manifold import TSNE\n",
    "import missingno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "\n",
    "path = './data/'\n",
    "train = pd.read_csv(path + 'train_features.csv')\n",
    "train_label = pd.read_csv(path + 'train_labels.csv')\n",
    "test = pd.read_csv(path + 'test_features.csv')\n",
    "submission = pd.read_csv(path + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-Processing Effect on the Accuracy of Event-Based Activity Segmentation and Classification through Inertial Sensors \n",
    "# https://www.researchgate.net/publication/281836367_Pre-Processing_Effect_on_the_Accuracy_of_Event-Based_Activity_Segmentation_and_Classification_through_Inertial_Sensors\n",
    "\n",
    "train['acc_t']  = train.apply(lambda x : (x['acc_x']**2 + x['acc_y'] **2 +  x['acc_z'] ** 2 )**(1/3), axis=1)\n",
    "test['acc_t']  = test.apply(lambda x : (x['acc_x']**2 + x['acc_y'] **2 +  x['acc_z'] ** 2 )**(1/3), axis=1)\n",
    "\n",
    "train['gy_t']  = train.apply(lambda x : (x['gy_x']**2 + x['gy_y'] **2 +  x['gy_z'] ** 2 )**(1/3), axis=1)\n",
    "test['gy_t']  = test.apply(lambda x : (x['gy_x']**2 + x['gy_y'] **2 +  x['gy_z'] ** 2 )**(1/3), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://dacon.io/competitions/official/235689/codeshare/2375?page=1&dtype=recent&ptype=pub\n",
    "# 간단한 LGBM으로 접근해보기\n",
    "\n",
    "X_pivot_train = pd.pivot_table(data = train, # X_train의 데이터를 통해서\n",
    "                               values = train.columns[2:],  # id와 time을 제외한 피쳐를 대상으로\n",
    "                               index = 'id', # id를 기준으로 잡아\n",
    "                               aggfunc = ['sum','mean',         # 합, 평균\n",
    "                                          'median','min','max', # 중앙값 최소값, 최대값\n",
    "                                          'std','var'           # 베셀 보정 표본 표준편차, 비편향 편차 의 값을 구합니다.\n",
    "                                         ]\n",
    "                              )\n",
    "\n",
    "X_pivot_test = pd.pivot_table(data = test, #\n",
    "                               values = test.columns[2:], \n",
    "                               index = 'id', # id를 기준으로 잡아\n",
    "                               aggfunc = ['sum','mean',        \n",
    "                                          'median','min','max',\n",
    "                                          'std','var'          \n",
    "                                         ]\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sum_acc_t</th>\n",
       "      <th>sum_acc_x</th>\n",
       "      <th>sum_acc_y</th>\n",
       "      <th>sum_acc_z</th>\n",
       "      <th>sum_gy_t</th>\n",
       "      <th>sum_gy_x</th>\n",
       "      <th>sum_gy_y</th>\n",
       "      <th>sum_gy_z</th>\n",
       "      <th>mean_acc_t</th>\n",
       "      <th>...</th>\n",
       "      <th>std_gy_z</th>\n",
       "      <th>var_acc_t</th>\n",
       "      <th>var_acc_x</th>\n",
       "      <th>var_acc_y</th>\n",
       "      <th>var_acc_z</th>\n",
       "      <th>var_gy_t</th>\n",
       "      <th>var_gy_x</th>\n",
       "      <th>var_gy_y</th>\n",
       "      <th>var_gy_z</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>619.171101</td>\n",
       "      <td>558.797337</td>\n",
       "      <td>-131.082711</td>\n",
       "      <td>-222.252919</td>\n",
       "      <td>5815.160027</td>\n",
       "      <td>-1119.161589</td>\n",
       "      <td>-2015.703683</td>\n",
       "      <td>709.264425</td>\n",
       "      <td>1.031952</td>\n",
       "      <td>...</td>\n",
       "      <td>25.275185</td>\n",
       "      <td>0.012741</td>\n",
       "      <td>0.036664</td>\n",
       "      <td>0.031375</td>\n",
       "      <td>0.018260</td>\n",
       "      <td>16.353172</td>\n",
       "      <td>176.470384</td>\n",
       "      <td>590.513292</td>\n",
       "      <td>638.834979</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>632.688598</td>\n",
       "      <td>-459.948117</td>\n",
       "      <td>-190.354639</td>\n",
       "      <td>-2.534051</td>\n",
       "      <td>12858.851545</td>\n",
       "      <td>6642.960123</td>\n",
       "      <td>1044.284884</td>\n",
       "      <td>835.976169</td>\n",
       "      <td>1.054481</td>\n",
       "      <td>...</td>\n",
       "      <td>75.545343</td>\n",
       "      <td>0.037258</td>\n",
       "      <td>0.245548</td>\n",
       "      <td>0.113175</td>\n",
       "      <td>0.249396</td>\n",
       "      <td>151.398806</td>\n",
       "      <td>6279.700472</td>\n",
       "      <td>9217.015511</td>\n",
       "      <td>5707.098884</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>593.195479</td>\n",
       "      <td>23.901616</td>\n",
       "      <td>-49.441742</td>\n",
       "      <td>375.607013</td>\n",
       "      <td>12864.850286</td>\n",
       "      <td>-5083.770868</td>\n",
       "      <td>358.725917</td>\n",
       "      <td>1831.974458</td>\n",
       "      <td>0.988659</td>\n",
       "      <td>...</td>\n",
       "      <td>13.920337</td>\n",
       "      <td>0.007896</td>\n",
       "      <td>0.506904</td>\n",
       "      <td>0.021646</td>\n",
       "      <td>0.061905</td>\n",
       "      <td>81.812660</td>\n",
       "      <td>646.325142</td>\n",
       "      <td>14150.683677</td>\n",
       "      <td>193.775778</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>585.741919</td>\n",
       "      <td>-532.621192</td>\n",
       "      <td>-52.600737</td>\n",
       "      <td>136.413976</td>\n",
       "      <td>7807.353545</td>\n",
       "      <td>10646.500409</td>\n",
       "      <td>2880.558352</td>\n",
       "      <td>-3521.938833</td>\n",
       "      <td>0.976237</td>\n",
       "      <td>...</td>\n",
       "      <td>23.647153</td>\n",
       "      <td>0.004687</td>\n",
       "      <td>0.017134</td>\n",
       "      <td>0.037639</td>\n",
       "      <td>0.042387</td>\n",
       "      <td>43.389223</td>\n",
       "      <td>1842.887012</td>\n",
       "      <td>1365.558625</td>\n",
       "      <td>559.187841</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>637.338408</td>\n",
       "      <td>-395.410844</td>\n",
       "      <td>-202.240064</td>\n",
       "      <td>121.654507</td>\n",
       "      <td>8067.185605</td>\n",
       "      <td>-2891.782899</td>\n",
       "      <td>5791.027696</td>\n",
       "      <td>2672.029417</td>\n",
       "      <td>1.062231</td>\n",
       "      <td>...</td>\n",
       "      <td>46.148326</td>\n",
       "      <td>0.031108</td>\n",
       "      <td>0.245193</td>\n",
       "      <td>0.325247</td>\n",
       "      <td>0.151824</td>\n",
       "      <td>221.765323</td>\n",
       "      <td>11719.982095</td>\n",
       "      <td>3662.008463</td>\n",
       "      <td>2129.668017</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3120</th>\n",
       "      <td>3120</td>\n",
       "      <td>588.797343</td>\n",
       "      <td>-180.272174</td>\n",
       "      <td>-401.525652</td>\n",
       "      <td>201.560530</td>\n",
       "      <td>5731.683639</td>\n",
       "      <td>-3229.789337</td>\n",
       "      <td>-2941.679051</td>\n",
       "      <td>-32.415360</td>\n",
       "      <td>0.981329</td>\n",
       "      <td>...</td>\n",
       "      <td>24.913819</td>\n",
       "      <td>0.006641</td>\n",
       "      <td>0.162550</td>\n",
       "      <td>0.035006</td>\n",
       "      <td>0.117825</td>\n",
       "      <td>67.859710</td>\n",
       "      <td>1324.702298</td>\n",
       "      <td>1457.382016</td>\n",
       "      <td>620.698354</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3121</th>\n",
       "      <td>3121</td>\n",
       "      <td>604.650076</td>\n",
       "      <td>-584.578686</td>\n",
       "      <td>-140.023548</td>\n",
       "      <td>-44.262826</td>\n",
       "      <td>5027.134552</td>\n",
       "      <td>6836.985564</td>\n",
       "      <td>2272.105392</td>\n",
       "      <td>-1675.342583</td>\n",
       "      <td>1.007750</td>\n",
       "      <td>...</td>\n",
       "      <td>12.786464</td>\n",
       "      <td>0.011917</td>\n",
       "      <td>0.028887</td>\n",
       "      <td>0.013767</td>\n",
       "      <td>0.007417</td>\n",
       "      <td>38.327494</td>\n",
       "      <td>1253.062926</td>\n",
       "      <td>238.087738</td>\n",
       "      <td>163.493653</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3122</th>\n",
       "      <td>3122</td>\n",
       "      <td>720.129478</td>\n",
       "      <td>-668.547732</td>\n",
       "      <td>-217.317785</td>\n",
       "      <td>144.910824</td>\n",
       "      <td>25470.832381</td>\n",
       "      <td>-2292.798232</td>\n",
       "      <td>6103.301689</td>\n",
       "      <td>-1033.698245</td>\n",
       "      <td>1.200216</td>\n",
       "      <td>...</td>\n",
       "      <td>131.916609</td>\n",
       "      <td>0.088040</td>\n",
       "      <td>0.467567</td>\n",
       "      <td>0.112211</td>\n",
       "      <td>0.044597</td>\n",
       "      <td>175.976939</td>\n",
       "      <td>22051.857079</td>\n",
       "      <td>57621.020319</td>\n",
       "      <td>17401.991847</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3123</th>\n",
       "      <td>3123</td>\n",
       "      <td>615.533707</td>\n",
       "      <td>-66.799727</td>\n",
       "      <td>528.216970</td>\n",
       "      <td>-73.654160</td>\n",
       "      <td>12758.593344</td>\n",
       "      <td>-3734.255616</td>\n",
       "      <td>-6965.012570</td>\n",
       "      <td>-3558.151108</td>\n",
       "      <td>1.025890</td>\n",
       "      <td>...</td>\n",
       "      <td>71.243150</td>\n",
       "      <td>0.008436</td>\n",
       "      <td>0.187248</td>\n",
       "      <td>0.046994</td>\n",
       "      <td>0.069216</td>\n",
       "      <td>63.795352</td>\n",
       "      <td>2582.777254</td>\n",
       "      <td>6398.528531</td>\n",
       "      <td>5075.586383</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3124</th>\n",
       "      <td>3124</td>\n",
       "      <td>599.996329</td>\n",
       "      <td>-260.428968</td>\n",
       "      <td>-373.805701</td>\n",
       "      <td>136.108687</td>\n",
       "      <td>10726.302446</td>\n",
       "      <td>-983.222826</td>\n",
       "      <td>-736.121776</td>\n",
       "      <td>-1948.094865</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>...</td>\n",
       "      <td>49.371117</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>0.272596</td>\n",
       "      <td>0.043506</td>\n",
       "      <td>0.059036</td>\n",
       "      <td>38.834889</td>\n",
       "      <td>339.778155</td>\n",
       "      <td>4877.798463</td>\n",
       "      <td>2437.507157</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3125 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id   sum_acc_t   sum_acc_x   sum_acc_y   sum_acc_z      sum_gy_t  \\\n",
       "0        0  619.171101  558.797337 -131.082711 -222.252919   5815.160027   \n",
       "1        1  632.688598 -459.948117 -190.354639   -2.534051  12858.851545   \n",
       "2        2  593.195479   23.901616  -49.441742  375.607013  12864.850286   \n",
       "3        3  585.741919 -532.621192  -52.600737  136.413976   7807.353545   \n",
       "4        4  637.338408 -395.410844 -202.240064  121.654507   8067.185605   \n",
       "...    ...         ...         ...         ...         ...           ...   \n",
       "3120  3120  588.797343 -180.272174 -401.525652  201.560530   5731.683639   \n",
       "3121  3121  604.650076 -584.578686 -140.023548  -44.262826   5027.134552   \n",
       "3122  3122  720.129478 -668.547732 -217.317785  144.910824  25470.832381   \n",
       "3123  3123  615.533707  -66.799727  528.216970  -73.654160  12758.593344   \n",
       "3124  3124  599.996329 -260.428968 -373.805701  136.108687  10726.302446   \n",
       "\n",
       "          sum_gy_x     sum_gy_y     sum_gy_z  mean_acc_t  ...    std_gy_z  \\\n",
       "0     -1119.161589 -2015.703683   709.264425    1.031952  ...   25.275185   \n",
       "1      6642.960123  1044.284884   835.976169    1.054481  ...   75.545343   \n",
       "2     -5083.770868   358.725917  1831.974458    0.988659  ...   13.920337   \n",
       "3     10646.500409  2880.558352 -3521.938833    0.976237  ...   23.647153   \n",
       "4     -2891.782899  5791.027696  2672.029417    1.062231  ...   46.148326   \n",
       "...            ...          ...          ...         ...  ...         ...   \n",
       "3120  -3229.789337 -2941.679051   -32.415360    0.981329  ...   24.913819   \n",
       "3121   6836.985564  2272.105392 -1675.342583    1.007750  ...   12.786464   \n",
       "3122  -2292.798232  6103.301689 -1033.698245    1.200216  ...  131.916609   \n",
       "3123  -3734.255616 -6965.012570 -3558.151108    1.025890  ...   71.243150   \n",
       "3124   -983.222826  -736.121776 -1948.094865    0.999994  ...   49.371117   \n",
       "\n",
       "      var_acc_t  var_acc_x  var_acc_y  var_acc_z    var_gy_t      var_gy_x  \\\n",
       "0      0.012741   0.036664   0.031375   0.018260   16.353172    176.470384   \n",
       "1      0.037258   0.245548   0.113175   0.249396  151.398806   6279.700472   \n",
       "2      0.007896   0.506904   0.021646   0.061905   81.812660    646.325142   \n",
       "3      0.004687   0.017134   0.037639   0.042387   43.389223   1842.887012   \n",
       "4      0.031108   0.245193   0.325247   0.151824  221.765323  11719.982095   \n",
       "...         ...        ...        ...        ...         ...           ...   \n",
       "3120   0.006641   0.162550   0.035006   0.117825   67.859710   1324.702298   \n",
       "3121   0.011917   0.028887   0.013767   0.007417   38.327494   1253.062926   \n",
       "3122   0.088040   0.467567   0.112211   0.044597  175.976939  22051.857079   \n",
       "3123   0.008436   0.187248   0.046994   0.069216   63.795352   2582.777254   \n",
       "3124   0.000848   0.272596   0.043506   0.059036   38.834889    339.778155   \n",
       "\n",
       "          var_gy_y      var_gy_z  label  \n",
       "0       590.513292    638.834979     37  \n",
       "1      9217.015511   5707.098884     26  \n",
       "2     14150.683677    193.775778      3  \n",
       "3      1365.558625    559.187841     26  \n",
       "4      3662.008463   2129.668017     26  \n",
       "...            ...           ...    ...  \n",
       "3120   1457.382016    620.698354     26  \n",
       "3121    238.087738    163.493653     26  \n",
       "3122  57621.020319  17401.991847     15  \n",
       "3123   6398.528531   5075.586383     26  \n",
       "3124   4877.798463   2437.507157      2  \n",
       "\n",
       "[3125 rows x 58 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_columns = [agg + '_' + column for agg,column in X_pivot_train.columns]\n",
    "X_pivot_train.columns = X_columns\n",
    "X_pivot_test.columns = X_columns\n",
    "X_pivot_train = X_pivot_train.reset_index()\n",
    "X_pivot_test = X_pivot_test.reset_index()\n",
    "\n",
    "train_data = pd.merge(X_pivot_train, train_label.loc[:,['id','label']], on='id') # label_desc는 사용하지 않을 예정입니다.\n",
    "train_data.label = train_data.label.astype('category')\n",
    "\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 푸리에 변환\n",
    "\n",
    "def ft_trans(name,train,test):\n",
    "    def train_test(check,num_col):\n",
    "\n",
    "        \n",
    "        if check =='train':\n",
    "            df_checking=train.copy()\n",
    "            train_datas = np.zeros((len(df_checking.id.unique()),304))\n",
    "            \n",
    "        elif check =='test':\n",
    "            df_checking=test.copy()\n",
    "            train_datas = np.zeros((len(df_checking.id.unique()),304))\n",
    "                       \n",
    "\n",
    "        for i,num in enumerate(tqdm(df_checking.id.unique())):\n",
    "\n",
    "            tt = df_checking.loc[df_checking.id==num][name] -df_checking.loc[df_checking.id==num][name].mean()\n",
    "            fmax = 50      # sampling frequency 1000 Hz\n",
    "            dt = 1/fmax      # sampling period\n",
    "            N  = 600      # length of signal\n",
    "\n",
    "            t  = np.arange(0,N)*dt   # time = [0, dt, ..., (N-1)*dt]\n",
    "            x = tt.values\n",
    "            df = fmax/N   # df = 1/N = fmax/N\n",
    "            f = np.arange(0,N)*df     #   frq = [0, df, ..., (N-1)*df]\n",
    "            xf = np.fft.fft(x)*dt\n",
    "            tq_index=f[0:int(N/2+1)]\n",
    "            tq_abs= np.abs(xf[0:int(N/2+1)])\n",
    "\n",
    "            results = pd.DataFrame(tq_abs,tq_index).reset_index().rename(columns={'index':'hz',0:'abs_value'})\n",
    "            \n",
    "            ar0 = np.array([num])\n",
    "            ar1 =results.abs_value.values\n",
    "            ar2 = np.array([skew(results.abs_value),kurtosis(results.abs_value, fisher=True)])\n",
    "            return_value = np.concatenate([ar0,ar1 ,ar2])    \n",
    "            train_datas[i] = return_value\n",
    "\n",
    "        return train_datas\n",
    "\n",
    "    \n",
    "    col_ft = ['_'+str(x) for x in range(304)]\n",
    "    \n",
    "    num_col = len(col_ft)\n",
    "    train_datas = train_test('train',num_col)\n",
    "    test_datas = train_test('test',num_col)\n",
    "    \n",
    "    col_ft_F = ['id']+[name+\"_\"+x for x in col_ft[1:]]        \n",
    "    train_df = pd.DataFrame(train_datas,columns= col_ft_F)\n",
    "    test_df = pd.DataFrame(test_datas,columns= col_ft_F)\n",
    "    \n",
    "    train_df.id = train_df.id.astype('int')\n",
    "    test_df.id = test_df.id.astype('int')\n",
    "    \n",
    "    \n",
    "    return train_df ,test_df\n",
    "\n",
    "# https://dacon.io/competitions/official/235689/codeshare/2374?page=1&dtype=recent&ptype=pub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3125/3125 [00:12<00:00, 242.11it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 782/782 [00:01<00:00, 477.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3125, 304), (782, 304))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fft,test_fft = ft_trans('acc_t',train,test)\n",
    "train_fft.shape, test_fft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "transformer_pivot = RobustScaler().fit(train_data.drop(['id', 'label'], axis=1))\n",
    "pivot_train = transformer_pivot.transform(train_data.drop(['id', 'label'], axis=1))\n",
    "pivot_test = transformer_pivot.transform(X_pivot_test.drop('id', axis=1))\n",
    "\n",
    "transformer_fft = RobustScaler().fit(train_fft)\n",
    "train_fft = transformer_fft.transform(train_fft)\n",
    "test_fft = transformer_fft.transform(test_fft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2번째 모델 : XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:3.56176\tvalid-mlogloss:3.58476\n",
      "[100]\ttrain-mlogloss:0.21011\tvalid-mlogloss:0.98174\n",
      "[200]\ttrain-mlogloss:0.05514\tvalid-mlogloss:0.87153\n",
      "[300]\ttrain-mlogloss:0.03116\tvalid-mlogloss:0.85338\n",
      "[400]\ttrain-mlogloss:0.02372\tvalid-mlogloss:0.84793\n",
      "[500]\ttrain-mlogloss:0.02040\tvalid-mlogloss:0.84682\n",
      "[600]\ttrain-mlogloss:0.01861\tvalid-mlogloss:0.84501\n",
      "[662]\ttrain-mlogloss:0.01786\tvalid-mlogloss:0.84505\n",
      "------------------\n",
      "[0]\ttrain-mlogloss:3.55079\tvalid-mlogloss:3.59125\n",
      "[100]\ttrain-mlogloss:0.20451\tvalid-mlogloss:1.06810\n",
      "[200]\ttrain-mlogloss:0.05383\tvalid-mlogloss:0.96120\n",
      "[300]\ttrain-mlogloss:0.03075\tvalid-mlogloss:0.94174\n",
      "[400]\ttrain-mlogloss:0.02356\tvalid-mlogloss:0.93376\n",
      "[500]\ttrain-mlogloss:0.02031\tvalid-mlogloss:0.93082\n",
      "[573]\ttrain-mlogloss:0.01892\tvalid-mlogloss:0.93143\n",
      "------------------\n",
      "[0]\ttrain-mlogloss:3.55553\tvalid-mlogloss:3.58545\n",
      "[100]\ttrain-mlogloss:0.20572\tvalid-mlogloss:0.94304\n",
      "[200]\ttrain-mlogloss:0.05450\tvalid-mlogloss:0.83961\n",
      "[300]\ttrain-mlogloss:0.03105\tvalid-mlogloss:0.82622\n",
      "[400]\ttrain-mlogloss:0.02373\tvalid-mlogloss:0.82364\n",
      "[500]\ttrain-mlogloss:0.02037\tvalid-mlogloss:0.82320\n",
      "[509]\ttrain-mlogloss:0.02017\tvalid-mlogloss:0.82295\n",
      "------------------\n",
      "[0]\ttrain-mlogloss:3.54561\tvalid-mlogloss:3.56872\n",
      "[100]\ttrain-mlogloss:0.20593\tvalid-mlogloss:0.98020\n",
      "[200]\ttrain-mlogloss:0.05437\tvalid-mlogloss:0.88942\n",
      "[300]\ttrain-mlogloss:0.03110\tvalid-mlogloss:0.87463\n",
      "[400]\ttrain-mlogloss:0.02378\tvalid-mlogloss:0.87185\n",
      "[500]\ttrain-mlogloss:0.02040\tvalid-mlogloss:0.87050\n",
      "[567]\ttrain-mlogloss:0.01909\tvalid-mlogloss:0.87043\n",
      "------------------\n",
      "[0]\ttrain-mlogloss:3.55912\tvalid-mlogloss:3.59368\n",
      "[100]\ttrain-mlogloss:0.20762\tvalid-mlogloss:0.96365\n",
      "[200]\ttrain-mlogloss:0.05450\tvalid-mlogloss:0.84321\n",
      "[300]\ttrain-mlogloss:0.03111\tvalid-mlogloss:0.82362\n",
      "[400]\ttrain-mlogloss:0.02372\tvalid-mlogloss:0.82077\n",
      "[497]\ttrain-mlogloss:0.02040\tvalid-mlogloss:0.81972\n",
      "------------------\n",
      "[0]\ttrain-mlogloss:3.56176\tvalid-mlogloss:3.58476\n",
      "[100]\ttrain-mlogloss:0.21011\tvalid-mlogloss:0.98174\n",
      "[200]\ttrain-mlogloss:0.05514\tvalid-mlogloss:0.87153\n",
      "[300]\ttrain-mlogloss:0.03116\tvalid-mlogloss:0.85338\n",
      "[400]\ttrain-mlogloss:0.02372\tvalid-mlogloss:0.84793\n",
      "[500]\ttrain-mlogloss:0.02040\tvalid-mlogloss:0.84682\n",
      "[600]\ttrain-mlogloss:0.01861\tvalid-mlogloss:0.84501\n",
      "[663]\ttrain-mlogloss:0.01785\tvalid-mlogloss:0.84513\n",
      "------------------\n",
      "[0]\ttrain-mlogloss:3.55079\tvalid-mlogloss:3.59125\n",
      "[100]\ttrain-mlogloss:0.20451\tvalid-mlogloss:1.06810\n",
      "[200]\ttrain-mlogloss:0.05383\tvalid-mlogloss:0.96120\n",
      "[300]\ttrain-mlogloss:0.03075\tvalid-mlogloss:0.94174\n",
      "[400]\ttrain-mlogloss:0.02356\tvalid-mlogloss:0.93376\n",
      "[500]\ttrain-mlogloss:0.02031\tvalid-mlogloss:0.93082\n",
      "[574]\ttrain-mlogloss:0.01890\tvalid-mlogloss:0.93150\n",
      "------------------\n",
      "[0]\ttrain-mlogloss:3.55553\tvalid-mlogloss:3.58545\n",
      "[100]\ttrain-mlogloss:0.20572\tvalid-mlogloss:0.94304\n",
      "[200]\ttrain-mlogloss:0.05450\tvalid-mlogloss:0.83961\n",
      "[300]\ttrain-mlogloss:0.03105\tvalid-mlogloss:0.82622\n",
      "[400]\ttrain-mlogloss:0.02373\tvalid-mlogloss:0.82364\n",
      "[500]\ttrain-mlogloss:0.02037\tvalid-mlogloss:0.82320\n",
      "[510]\ttrain-mlogloss:0.02014\tvalid-mlogloss:0.82289\n",
      "------------------\n",
      "[0]\ttrain-mlogloss:3.54561\tvalid-mlogloss:3.56872\n",
      "[100]\ttrain-mlogloss:0.20593\tvalid-mlogloss:0.98020\n",
      "[200]\ttrain-mlogloss:0.05437\tvalid-mlogloss:0.88942\n",
      "[300]\ttrain-mlogloss:0.03110\tvalid-mlogloss:0.87463\n",
      "[400]\ttrain-mlogloss:0.02378\tvalid-mlogloss:0.87185\n",
      "[500]\ttrain-mlogloss:0.02040\tvalid-mlogloss:0.87050\n",
      "[567]\ttrain-mlogloss:0.01909\tvalid-mlogloss:0.87043\n",
      "------------------\n",
      "[0]\ttrain-mlogloss:3.55912\tvalid-mlogloss:3.59368\n",
      "[100]\ttrain-mlogloss:0.20762\tvalid-mlogloss:0.96365\n",
      "[200]\ttrain-mlogloss:0.05450\tvalid-mlogloss:0.84321\n",
      "[300]\ttrain-mlogloss:0.03111\tvalid-mlogloss:0.82362\n",
      "[400]\ttrain-mlogloss:0.02372\tvalid-mlogloss:0.82077\n",
      "[497]\ttrain-mlogloss:0.02040\tvalid-mlogloss:0.81972\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "# 모델 2번: xgboost\n",
    "\n",
    "def build_xgboost(split_num, train, target, test, rnd):\n",
    "    \n",
    "    params = {\n",
    "                'colsample_bytree': 0.7,\n",
    "                'subsample': 0.8,\n",
    "                'eta': 0.04,\n",
    "                'max_depth': 12,\n",
    "                'eval_metric':'mlogloss',\n",
    "                'objective':'multi:softprob',\n",
    "                'num_class':61,\n",
    "                }\n",
    "    \n",
    "    # return train pred prob and test pred prob \n",
    "    train_pred, test_pred = np.zeros((train.shape[0], 61)), np.zeros((test.shape[0], 61))\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=split_num, shuffle=True, random_state=233*rnd)\n",
    "    for train_idx, val_idx in skf.split(train, target):\n",
    "\n",
    "        # split train, validation set\n",
    "        X = train[train_idx]\n",
    "        y = target[train_idx]\n",
    "        valid_x = train[val_idx]\n",
    "        valid_y = target[val_idx]\n",
    "\n",
    "        d_train = xgb.DMatrix(X, y)\n",
    "        d_valid = xgb.DMatrix(valid_x, valid_y)\n",
    "        d_temp = xgb.DMatrix(valid_x)\n",
    "        d_test = xgb.DMatrix(test)\n",
    "        \n",
    "        watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "        \n",
    "        #run traning\n",
    "        model = xgb.train(params, d_train, 2000, watchlist, \n",
    "                        early_stopping_rounds=50,\n",
    "                        verbose_eval=100)\n",
    "\n",
    "        # save feat\n",
    "        train_pred[val_idx] = model.predict(d_temp)\n",
    "        test_pred += model.predict(d_test)/split_num\n",
    "        \n",
    "        # release\n",
    "        del model\n",
    "        gc.collect()\n",
    "        print('  ==============================================================  ')\n",
    "        \n",
    "    return train_pred, test_pred\n",
    "\n",
    "xgb_train1, xgb_test1 = build_xgboost(5, np.array(pivot_train), np.array(train_data.label), np.array(pivot_test), 1)\n",
    "xgb_train2, xgb_test2 = build_xgboost(5, np.array(pivot_train), np.array(train_data.label), np.array(pivot_test), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3번째 모델 : CATBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 3.9378090\ttest: 3.9375637\tbest: 3.9375637 (0)\ttotal: 28.3ms\tremaining: 4m 42s\n",
      "500:\tlearn: 1.0395626\ttest: 1.2650794\tbest: 1.2650794 (500)\ttotal: 12.2s\tremaining: 3m 51s\n",
      "1000:\tlearn: 0.6696813\ttest: 1.0079386\tbest: 1.0079386 (1000)\ttotal: 24.7s\tremaining: 3m 42s\n",
      "1500:\tlearn: 0.4865061\ttest: 0.8980774\tbest: 0.8980774 (1500)\ttotal: 37.1s\tremaining: 3m 29s\n",
      "2000:\tlearn: 0.3758241\ttest: 0.8372569\tbest: 0.8372569 (2000)\ttotal: 49.3s\tremaining: 3m 16s\n",
      "2500:\tlearn: 0.2988821\ttest: 0.7996224\tbest: 0.7996224 (2500)\ttotal: 1m 1s\tremaining: 3m 4s\n",
      "3000:\tlearn: 0.2424718\ttest: 0.7724925\tbest: 0.7724925 (3000)\ttotal: 1m 13s\tremaining: 2m 51s\n",
      "3500:\tlearn: 0.2004491\ttest: 0.7543519\tbest: 0.7543519 (3500)\ttotal: 1m 25s\tremaining: 2m 38s\n",
      "4000:\tlearn: 0.1686975\ttest: 0.7408762\tbest: 0.7408548 (3999)\ttotal: 1m 37s\tremaining: 2m 26s\n",
      "4500:\tlearn: 0.1446332\ttest: 0.7313281\tbest: 0.7313132 (4499)\ttotal: 1m 49s\tremaining: 2m 14s\n",
      "5000:\tlearn: 0.1257219\ttest: 0.7232240\tbest: 0.7232240 (5000)\ttotal: 2m 1s\tremaining: 2m 1s\n",
      "5500:\tlearn: 0.1104435\ttest: 0.7175404\tbest: 0.7175362 (5499)\ttotal: 2m 13s\tremaining: 1m 49s\n",
      "6000:\tlearn: 0.0980180\ttest: 0.7125500\tbest: 0.7125429 (5998)\ttotal: 2m 25s\tremaining: 1m 36s\n",
      "6500:\tlearn: 0.0876357\ttest: 0.7088862\tbest: 0.7088776 (6499)\ttotal: 2m 37s\tremaining: 1m 24s\n",
      "7000:\tlearn: 0.0789449\ttest: 0.7060477\tbest: 0.7060477 (7000)\ttotal: 2m 48s\tremaining: 1m 12s\n",
      "7500:\tlearn: 0.0717756\ttest: 0.7038792\tbest: 0.7038733 (7493)\ttotal: 3m\tremaining: 1m\n",
      "8000:\tlearn: 0.0655743\ttest: 0.7019317\tbest: 0.7019317 (8000)\ttotal: 3m 12s\tremaining: 48.1s\n",
      "8500:\tlearn: 0.0602087\ttest: 0.7002263\tbest: 0.7002162 (8478)\ttotal: 3m 24s\tremaining: 36.1s\n",
      "9000:\tlearn: 0.0556475\ttest: 0.6990795\tbest: 0.6990772 (8997)\ttotal: 3m 36s\tremaining: 24s\n",
      "9500:\tlearn: 0.0516432\ttest: 0.6979931\tbest: 0.6979931 (9500)\ttotal: 3m 48s\tremaining: 12s\n",
      "bestTest = 0.6971867188\n",
      "bestIteration = 9811\n",
      "Shrink model to first 9812 iterations.\n",
      "------------------\n",
      "0:\tlearn: 3.9171762\ttest: 3.9235930\tbest: 3.9235930 (0)\ttotal: 26.6ms\tremaining: 4m 25s\n",
      "500:\tlearn: 1.0199270\ttest: 1.3166129\tbest: 1.3166129 (500)\ttotal: 12s\tremaining: 3m 48s\n",
      "1000:\tlearn: 0.6569898\ttest: 1.0820361\tbest: 1.0820361 (1000)\ttotal: 24.4s\tremaining: 3m 39s\n",
      "1500:\tlearn: 0.4719089\ttest: 0.9814148\tbest: 0.9814148 (1500)\ttotal: 36.5s\tremaining: 3m 26s\n",
      "2000:\tlearn: 0.3618688\ttest: 0.9281426\tbest: 0.9281426 (2000)\ttotal: 48.5s\tremaining: 3m 13s\n",
      "2500:\tlearn: 0.2862115\ttest: 0.8952980\tbest: 0.8952980 (2500)\ttotal: 1m\tremaining: 3m 1s\n",
      "3000:\tlearn: 0.2324427\ttest: 0.8741520\tbest: 0.8741520 (3000)\ttotal: 1m 12s\tremaining: 2m 48s\n",
      "3500:\tlearn: 0.1910262\ttest: 0.8576724\tbest: 0.8576724 (3500)\ttotal: 1m 24s\tremaining: 2m 36s\n",
      "4000:\tlearn: 0.1611409\ttest: 0.8467598\tbest: 0.8467598 (4000)\ttotal: 1m 36s\tremaining: 2m 23s\n",
      "4500:\tlearn: 0.1383755\ttest: 0.8386119\tbest: 0.8386119 (4500)\ttotal: 1m 47s\tremaining: 2m 11s\n",
      "5000:\tlearn: 0.1201815\ttest: 0.8329399\tbest: 0.8329399 (5000)\ttotal: 1m 59s\tremaining: 1m 59s\n",
      "5500:\tlearn: 0.1055783\ttest: 0.8289079\tbest: 0.8289079 (5500)\ttotal: 2m 11s\tremaining: 1m 47s\n",
      "6000:\tlearn: 0.0933978\ttest: 0.8260660\tbest: 0.8260439 (5988)\ttotal: 2m 23s\tremaining: 1m 35s\n",
      "bestTest = 0.8259770508\n",
      "bestIteration = 6008\n",
      "Shrink model to first 6009 iterations.\n",
      "------------------\n",
      "0:\tlearn: 3.9477055\ttest: 3.9441309\tbest: 3.9441309 (0)\ttotal: 26.1ms\tremaining: 4m 21s\n",
      "500:\tlearn: 1.0431965\ttest: 1.1991654\tbest: 1.1991654 (500)\ttotal: 12.1s\tremaining: 3m 50s\n",
      "1000:\tlearn: 0.6795182\ttest: 0.9651505\tbest: 0.9651505 (1000)\ttotal: 24.3s\tremaining: 3m 38s\n",
      "1500:\tlearn: 0.4890408\ttest: 0.8640534\tbest: 0.8640534 (1500)\ttotal: 36.3s\tremaining: 3m 25s\n",
      "2000:\tlearn: 0.3708595\ttest: 0.8104884\tbest: 0.8104884 (2000)\ttotal: 48.3s\tremaining: 3m 13s\n",
      "2500:\tlearn: 0.2916046\ttest: 0.7800062\tbest: 0.7800062 (2500)\ttotal: 1m\tremaining: 3m\n",
      "3000:\tlearn: 0.2353510\ttest: 0.7601531\tbest: 0.7601531 (3000)\ttotal: 1m 12s\tremaining: 2m 48s\n",
      "3500:\tlearn: 0.1941132\ttest: 0.7477162\tbest: 0.7477162 (3500)\ttotal: 1m 23s\tremaining: 2m 35s\n",
      "4000:\tlearn: 0.1629645\ttest: 0.7382604\tbest: 0.7382604 (4000)\ttotal: 1m 35s\tremaining: 2m 23s\n",
      "4500:\tlearn: 0.1393390\ttest: 0.7321349\tbest: 0.7321349 (4500)\ttotal: 1m 47s\tremaining: 2m 11s\n",
      "5000:\tlearn: 0.1206039\ttest: 0.7274422\tbest: 0.7274348 (4999)\ttotal: 1m 59s\tremaining: 1m 59s\n",
      "5500:\tlearn: 0.1059074\ttest: 0.7237587\tbest: 0.7237587 (5500)\ttotal: 2m 11s\tremaining: 1m 47s\n",
      "6000:\tlearn: 0.0939162\ttest: 0.7211191\tbest: 0.7211191 (6000)\ttotal: 2m 22s\tremaining: 1m 35s\n",
      "6500:\tlearn: 0.0844361\ttest: 0.7192795\tbest: 0.7192426 (6494)\ttotal: 2m 34s\tremaining: 1m 23s\n",
      "7000:\tlearn: 0.0762020\ttest: 0.7176859\tbest: 0.7176626 (6995)\ttotal: 2m 46s\tremaining: 1m 11s\n",
      "bestTest = 0.7174305664\n",
      "bestIteration = 7108\n",
      "Shrink model to first 7109 iterations.\n",
      "------------------\n",
      "0:\tlearn: 3.9147074\ttest: 3.9181984\tbest: 3.9181984 (0)\ttotal: 24.5ms\tremaining: 4m 5s\n",
      "500:\tlearn: 1.0351598\ttest: 1.2571850\tbest: 1.2571850 (500)\ttotal: 12s\tremaining: 3m 46s\n",
      "1000:\tlearn: 0.6777628\ttest: 1.0066785\tbest: 1.0066785 (1000)\ttotal: 24.1s\tremaining: 3m 36s\n",
      "1500:\tlearn: 0.4878259\ttest: 0.8927949\tbest: 0.8927949 (1500)\ttotal: 36.2s\tremaining: 3m 24s\n",
      "2000:\tlearn: 0.3755193\ttest: 0.8308746\tbest: 0.8308746 (2000)\ttotal: 48.1s\tremaining: 3m 12s\n",
      "2500:\tlearn: 0.2986529\ttest: 0.7910976\tbest: 0.7910976 (2500)\ttotal: 1m\tremaining: 3m\n",
      "3000:\tlearn: 0.2421666\ttest: 0.7637401\tbest: 0.7637401 (3000)\ttotal: 1m 11s\tremaining: 2m 47s\n",
      "3500:\tlearn: 0.2001917\ttest: 0.7447010\tbest: 0.7447010 (3500)\ttotal: 1m 23s\tremaining: 2m 35s\n",
      "4000:\tlearn: 0.1693956\ttest: 0.7315329\tbest: 0.7315329 (4000)\ttotal: 1m 35s\tremaining: 2m 23s\n",
      "4500:\tlearn: 0.1453420\ttest: 0.7220654\tbest: 0.7220654 (4500)\ttotal: 1m 47s\tremaining: 2m 10s\n",
      "5000:\tlearn: 0.1265847\ttest: 0.7153302\tbest: 0.7153302 (5000)\ttotal: 1m 58s\tremaining: 1m 58s\n",
      "5500:\tlearn: 0.1112749\ttest: 0.7094130\tbest: 0.7093913 (5497)\ttotal: 2m 10s\tremaining: 1m 46s\n",
      "6000:\tlearn: 0.0989294\ttest: 0.7051449\tbest: 0.7051449 (6000)\ttotal: 2m 22s\tremaining: 1m 34s\n",
      "6500:\tlearn: 0.0885388\ttest: 0.7016537\tbest: 0.7016537 (6500)\ttotal: 2m 34s\tremaining: 1m 23s\n",
      "7000:\tlearn: 0.0799100\ttest: 0.6986026\tbest: 0.6986026 (7000)\ttotal: 2m 46s\tremaining: 1m 11s\n",
      "7500:\tlearn: 0.0725799\ttest: 0.6967095\tbest: 0.6967095 (7500)\ttotal: 2m 57s\tremaining: 59.3s\n",
      "bestTest = 0.6959692871\n",
      "bestIteration = 7733\n",
      "Shrink model to first 7734 iterations.\n",
      "------------------\n",
      "0:\tlearn: 3.9463660\ttest: 3.9554039\tbest: 3.9554039 (0)\ttotal: 26.3ms\tremaining: 4m 22s\n",
      "500:\tlearn: 1.0437648\ttest: 1.2373203\tbest: 1.2373203 (500)\ttotal: 11.9s\tremaining: 3m 46s\n",
      "1000:\tlearn: 0.6777742\ttest: 0.9913662\tbest: 0.9913662 (1000)\ttotal: 24.1s\tremaining: 3m 36s\n",
      "1500:\tlearn: 0.4928532\ttest: 0.8824845\tbest: 0.8824845 (1500)\ttotal: 36s\tremaining: 3m 23s\n",
      "2000:\tlearn: 0.3768880\ttest: 0.8216237\tbest: 0.8216237 (2000)\ttotal: 47.9s\tremaining: 3m 11s\n",
      "2500:\tlearn: 0.2977116\ttest: 0.7858050\tbest: 0.7858050 (2500)\ttotal: 59.7s\tremaining: 2m 59s\n",
      "3000:\tlearn: 0.2408313\ttest: 0.7609239\tbest: 0.7609239 (3000)\ttotal: 1m 11s\tremaining: 2m 46s\n",
      "3500:\tlearn: 0.1989196\ttest: 0.7444163\tbest: 0.7444163 (3500)\ttotal: 1m 23s\tremaining: 2m 34s\n",
      "4000:\tlearn: 0.1671548\ttest: 0.7321379\tbest: 0.7321379 (4000)\ttotal: 1m 35s\tremaining: 2m 22s\n",
      "4500:\tlearn: 0.1428201\ttest: 0.7227642\tbest: 0.7227642 (4500)\ttotal: 1m 47s\tremaining: 2m 10s\n",
      "5000:\tlearn: 0.1232522\ttest: 0.7152388\tbest: 0.7152388 (5000)\ttotal: 1m 58s\tremaining: 1m 58s\n",
      "5500:\tlearn: 0.1082583\ttest: 0.7098692\tbest: 0.7098691 (5499)\ttotal: 2m 10s\tremaining: 1m 46s\n",
      "6000:\tlearn: 0.0956753\ttest: 0.7051477\tbest: 0.7051477 (6000)\ttotal: 2m 22s\tremaining: 1m 34s\n",
      "6500:\tlearn: 0.0853892\ttest: 0.7021839\tbest: 0.7021839 (6500)\ttotal: 2m 34s\tremaining: 1m 23s\n",
      "7000:\tlearn: 0.0771320\ttest: 0.7002842\tbest: 0.7002817 (6996)\ttotal: 2m 46s\tremaining: 1m 11s\n",
      "7500:\tlearn: 0.0701345\ttest: 0.6986644\tbest: 0.6986644 (7500)\ttotal: 2m 57s\tremaining: 59.3s\n",
      "bestTest = 0.6980544922\n",
      "bestIteration = 7721\n",
      "Shrink model to first 7722 iterations.\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "# 모델 3번: catboost\n",
    "\n",
    "def build_catboost(split_num, train, target, test, rnd):\n",
    "    # return train pred prob and test pred prob\n",
    "    train_pred, test_pred = np.zeros((train.shape[0], 61)), np.zeros((test.shape[0], 61))\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=split_num, shuffle=True, random_state=233*rnd)\n",
    "    for train_idx, val_idx in skf.split(train, target):\n",
    "\n",
    "        # split train, validation set\n",
    "        X = train[train_idx]\n",
    "        y = target.iloc[train_idx]\n",
    "        valid_x = train[val_idx]\n",
    "        valid_y = target.iloc[val_idx]\n",
    "\n",
    "        model = cb.CatBoostClassifier(iterations=10000,\n",
    "                                      learning_rate=0.01,\n",
    "                                      l2_leaf_reg=3.5,\n",
    "                                      depth=6,\n",
    "                                      loss_function= 'MultiClass',\n",
    "                                      eval_metric='MultiClass',\n",
    "                                      use_best_model=True,\n",
    "                                      random_seed=42,\n",
    "                                      verbose=500,\n",
    "                                      task_type=\"GPU\")\n",
    "\n",
    "        model.fit(X, y,\n",
    "                  eval_set=(valid_x, valid_y),\n",
    "                  early_stopping_rounds=50)\n",
    "        \n",
    "        # save feat\n",
    "        train_pred[val_idx] = model.predict(valid_x)\n",
    "        test_pred += model.predict_proba(test)/split_num\n",
    "        \n",
    "        # release\n",
    "        del model\n",
    "        gc.collect()\n",
    "        print('------------------')\n",
    "        \n",
    "    return train_pred, test_pred\n",
    "\n",
    "catboost_train1, catboost_test1 = build_catboost(5, pivot_train, train_data.label, pivot_test, 1)\n",
    "catboost_train2, catboost_test2 = build_catboost(5, pivot_train, train_data.label, pivot_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_submssion = pd.read_csv(path + 'sample_submission.csv')\n",
    "# sample_submssion.iloc[:,1:] = catboost_test1\n",
    "# sample_submssion.to_csv(\"catboost.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3번째 모델 : LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3125, 63)\n",
      "(782, 63)\n"
     ]
    }
   ],
   "source": [
    "xgb1_onehot = np.argmax(xgb_train1, axis=1).reshape(-1,1)\n",
    "xgb2_onehot = np.argmax(xgb_train2, axis=1).reshape(-1,1)\n",
    "catboost1_onehot = np.argmax(catboost_train1, axis=1).reshape(-1,1)\n",
    "catboost2_onehot = np.argmax(catboost_train2, axis=1).reshape(-1,1)\n",
    "# lgb1_onehot = np.argmax(lgb_train1, axis=1).reshape(-1,1)\n",
    "# lgb2_onehot = np.argmax(lgb_train2, axis=1).reshape(-1,1)\n",
    "\n",
    "xgb1_onehot_test = np.argmax(xgb_test1, axis=1).reshape(-1,1)\n",
    "xgb2_onehot_test = np.argmax(xgb_test2, axis=1).reshape(-1,1)\n",
    "catboost1_onehot_test = np.argmax(catboost_test1, axis=1).reshape(-1,1)\n",
    "catboost2_onehot_test = np.argmax(catboost_test2, axis=1).reshape(-1,1)\n",
    "# lgb1_onehot_test = np.argmax(lgb_test1, axis=1).reshape(-1,1)\n",
    "# lgb2_onehot_test = np.argmax(lgb_test2, axis=1).reshape(-1,1)\n",
    "\n",
    "train_final = np.hstack([xgb1_onehot, xgb2_onehot,\n",
    "                         catboost_train1])\n",
    "#                          lgb1_onehot, lgb2_onehot])\n",
    "\n",
    "test_final = np.hstack([xgb1_onehot_test, xgb2_onehot_test,\n",
    "                        catboost_test1])\n",
    "#                         lgb1_onehot_test, lgb2_onehot_test])\n",
    "\n",
    "print(train_final.shape)\n",
    "print(test_final.shape)\n",
    "\n",
    "# https://m.blog.naver.com/PostView.nhn?blogId=wideeyed&logNo=221343373342&proxyReferer=https:%2F%2Fwww.google.com%2F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:3.53030\tvalid-mlogloss:3.53577\n",
      "[100]\ttrain-mlogloss:0.87806\tvalid-mlogloss:1.12807\n",
      "[187]\ttrain-mlogloss:0.79313\tvalid-mlogloss:1.12446\n",
      "------------------\n",
      "[0]\ttrain-mlogloss:3.53543\tvalid-mlogloss:3.53955\n",
      "[100]\ttrain-mlogloss:0.89676\tvalid-mlogloss:1.08027\n",
      "[200]\ttrain-mlogloss:0.80460\tvalid-mlogloss:1.07546\n",
      "[202]\ttrain-mlogloss:0.80377\tvalid-mlogloss:1.07581\n",
      "------------------\n",
      "[0]\ttrain-mlogloss:3.52972\tvalid-mlogloss:3.54448\n",
      "[100]\ttrain-mlogloss:0.87049\tvalid-mlogloss:1.17482\n",
      "[165]\ttrain-mlogloss:0.79719\tvalid-mlogloss:1.18287\n",
      "------------------\n",
      "[0]\ttrain-mlogloss:3.53118\tvalid-mlogloss:3.53613\n",
      "[100]\ttrain-mlogloss:0.89716\tvalid-mlogloss:1.08300\n",
      "[200]\ttrain-mlogloss:0.80831\tvalid-mlogloss:1.06700\n",
      "[218]\ttrain-mlogloss:0.80202\tvalid-mlogloss:1.06742\n",
      "------------------\n",
      "[0]\ttrain-mlogloss:3.53902\tvalid-mlogloss:3.54060\n",
      "[100]\ttrain-mlogloss:0.91778\tvalid-mlogloss:1.00202\n",
      "[199]\ttrain-mlogloss:0.82698\tvalid-mlogloss:0.99122\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "# 최종 앙상블\n",
    "\n",
    "def ensemble_xgb(split_num, train, target, test):\n",
    "\n",
    "    test_pred = np.zeros((test.shape[0], 61))\n",
    "    \n",
    "    params = {\n",
    "                'colsample_bytree': 0.7,\n",
    "                'subsample': 0.8,\n",
    "                'eta': 0.04,\n",
    "                'max_depth': 12,\n",
    "                'eval_metric':'mlogloss',\n",
    "                'objective':'multi:softprob',\n",
    "                'num_class':61,\n",
    "                }\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=split_num, shuffle=True, random_state=2021)\n",
    "    for train_idx, val_idx in skf.split(train, target):\n",
    "\n",
    "        # split train, validation set\n",
    "        X = train[train_idx]\n",
    "        y = target[train_idx]\n",
    "        valid_x = train[val_idx]\n",
    "        valid_y = target[val_idx]\n",
    "        \n",
    "        d_train = xgb.DMatrix(X, y)\n",
    "        d_valid = xgb.DMatrix(valid_x, valid_y)\n",
    "        d_test = xgb.DMatrix(test)\n",
    "        \n",
    "        watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "        \n",
    "        #run traning\n",
    "        model = xgb.train(params, d_train, 2000, watchlist, \n",
    "                        early_stopping_rounds=50,\n",
    "                        verbose_eval=100)\n",
    "\n",
    "        # save feat\n",
    "        test_pred += model.predict(d_test)/split_num\n",
    "        \n",
    "        # release\n",
    "        del model\n",
    "        gc.collect()\n",
    "        print('------------------')\n",
    "    \n",
    "    sample_submssion = pd.read_csv(path + 'sample_submission.csv')\n",
    "    sample_submssion.iloc[:,1:] = test_pred\n",
    "    sample_submssion.to_csv(\"ensemble.csv\", index = False)\n",
    "        \n",
    "ensemble_xgb(5, train_final, np.array(train_data.label), test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
